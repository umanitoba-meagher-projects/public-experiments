{"cells":[{"cell_type":"markdown","metadata":{"id":"KfouixaEuDwg"},"source":["<a target=\"_blank\" href=\"https://colab.research.google.com/github/umanitoba-meagher-projects/public-experiments/blob/main/jupyter-notebooks/Visualize%20Image%20Information/sightings-bar-graph.ipynb\">\n","  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n","</a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jzM2rAlkFym4"},"outputs":[],"source":["\"\"\"\n","Author: Ryleigh J. Bruce\n","Date: June 11, 2024\n","\n","Purpose: To create several bar graphs depicting the volume of animal sightings per location across, months, seasons, and species.\n","\n","\n","Note: The author generated this text in part with GPT-4,\n","OpenAI’s large-scale language-generation model. Upon generating\n","draft code, the authors reviewed, edited, and revised the code\n","to their own liking and takes ultimate responsibility for\n","the content of this code.\n","\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"lVVn59HDuDwl"},"source":["# Introduction\n","\n","This notebook provides a systematic approach to visualizing animal sighting data across various locations, months, seasons, and species. The primary objective is to transform raw observational data into interpretable bar graphs that reveal patterns in animal presence and distribution. The workflow begins by downloading the dataset from the Borealis repository using their API, followed by importing essential Python libraries such as pandas and matplotlib for data manipulation and visualization. The dataset, which is structured as an Excel file, is loaded into a DataFrame, and preliminary data checks are performed to ensure integrity. The methodology involves extracting temporal features (such as month and season) from date fields, aggregating sighting counts by relevant categories (location, month, season, species), and generating grouped bar plots to illustrate these aggregations. Each section of the notebook is modular, focusing on a specific aspect of the data—monthly, seasonal, and species-based analyses—using consistent data processing and plotting techniques. The notebook emphasizes reproducibility and clarity, with markdown explanations accompanying each code block to guide users through the logic and purpose of each step. The benefits of this approach include the ability to quickly identify spatial and temporal trends in animal sightings, support for further ecological or spatial analysis, and adaptability for use with different datasets or research questions. The notebook is structured to be accessible for users with varying levels of experience in Python and data analysis, serving both as a practical tool for data exploration and as an educational resource for understanding the application of Python in ecological data visualization."]},{"cell_type":"markdown","metadata":{"id":"VOziKgHGuDwl"},"source":["# Critical Uses & Adaptability\n","\n","## What the Notebooks Can Be Used For:\n","\n","- **Dataset Exploration:**\n","  - Enables users to examine the distribution and frequency of animal sightings across different spatial and temporal dimensions. The notebook's aggregation and plotting steps (see code blocks for grouping and plotting) facilitate the identification of trends and anomalies in the dataset.\n","\n","- **Educational Purposes & Demonstrations:**\n","  - Serves as a resource for demonstrating the use of Python code, scripting, and basic data analysis techniques in the context of ecological or image-based datasets. The notebook includes step-by-step explanations and code for data loading, transformation, and visualization, making it suitable for instructional settings or self-guided learning. It also introduces foundational concepts relevant to machine learning workflows, such as feature extraction and data aggregation.\n","\n","- **Feature Extraction:**\n","  - Illustrates how to derive new variables (e.g., month, season, total sightings) from raw data fields. These derived features are used for further analysis and visualization, as shown in the code blocks that create new DataFrame columns and perform groupby operations.\n","\n","## How the Notebook Can Be Adapted:\n","\n","- **Integration with Spatial Design & Architectural Studies:**\n","  - The notebook's approach to aggregating and visualizing spatial data can be applied to site analysis tasks in spatial design or architecture. By swapping the animal sighting dataset with spatial or architectural datasets, users can analyze patterns such as foot traffic, environmental features, or usage intensity across locations and time periods.\n","\n","- **Variables & Customization:**\n","  - Variables such as 'locationID', 'Date', 'SpeciesList', and count columns are explicitly defined and can be modified to match the schema of alternative datasets. Users can adjust aggregation keys or add new features as needed for their specific analysis goals.\n","\n","- **Swapping Datasets:**\n","  - The notebook is designed to accommodate different datasets by changing the file path and ensuring the new dataset contains compatible columns. The code block responsible for loading the dataset (see the cell beginning with `file_path = ...` and `df = pd.read_excel(file_path)`) can be edited to point to a custom dataset, provided the necessary columns are present or appropriately renamed.\n","\n","- **Scalability:**\n","  - The modular structure of the notebook allows for the addition of new analysis sections or the scaling up of existing ones to handle larger datasets or more complex grouping variables. The use of pandas and matplotlib ensures compatibility with large data volumes and supports further extension with additional Python libraries if required."]},{"cell_type":"markdown","metadata":{"id":"QWKvExQ5s37a"},"source":["## Module: Borealis Data Repository Integration"]},{"cell_type":"markdown","metadata":{"id":"pCQJGOjZs5KX"},"source":["Here the Borealis API is queried to retrieve and download the dataset (combined_animals.xlsx) from the public repository. Utility functions are defined for checking, downloading, and unzipping files as needed. Additionally, we download the image data that will be used to train our machine learning model. The data is hosted in the University of Manitoba Dataverse (https://borealisdata.ca/dataverse/manitoba), a research data repository. The images used in this notebook were collected as part of the 'Understanding Animals' project at University of Manitoba Faculty of Architecture, online at Wild Winnipeg and Teaching with Images."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aVHZ8ZCUs9cK"},"outputs":[],"source":["# Borealis API configuration\n","import requests\n","import zipfile\n","import os\n","import shutil\n","import pandas as pd\n","\n","BOREALIS_SERVER = \"https://borealisdata.ca\"\n","\n","def get_public_dataset_info(persistent_id):\n","    \"\"\"\n","    Get information about a public dataset\n","    \"\"\"\n","    url = f\"{BOREALIS_SERVER}/api/datasets/:persistentId/\"\n","    params = {\"persistentId\": persistent_id}\n","\n","    response = requests.get(url, params=params)\n","\n","    if response.status_code == 200:\n","        dataset_info = response.json()\n","    else:\n","        print(f\"Cannot access dataset: {response.status_code}\")\n","        return None\n","\n","    \"\"\"\n","    Get a list of files in a public dataset\n","    \"\"\"\n","    # Access the list of files from the dataset_info dictionary\n","    files_list = dataset_info['data']['latestVersion']['files']\n","\n","    # Create an empty list to store file information\n","    file_info_list = []\n","\n","    # Iterate through the files list and append file ID and filename to the list\n","    for file_info in files_list:\n","        file_id = file_info['dataFile']['id']\n","        filename = file_info['dataFile']['filename']\n","        file_info_list.append({\"file_id\": file_id, \"filename\": filename})\n","\n","    return file_info_list\n","\n","def download_public_file(file_id, filename=None, save_path=\"./\"):\n","    \"\"\"\n","    Download a specific public file from a dataset by its file ID\n","    No authentication required\n","    \"\"\"\n","    url = f\"{BOREALIS_SERVER}/api/access/datafile/{file_id}\"\n","\n","    response = requests.get(url, stream=True)\n","\n","    if response.status_code == 200:\n","        # Use provided filename or try to determine from headers\n","        if not filename:\n","            if \"Content-Disposition\" in response.headers:\n","                cd = response.headers[\"Content-Disposition\"]\n","                if \"filename=\" in cd:\n","                    filename = cd.split(\"filename=\")[1].strip('\"')\n","\n","            # Fallback to file ID if no filename found\n","            if not filename:\n","                filename = str(file_id)\n","\n","        file_path = os.path.join(save_path, filename)\n","\n","        with open(file_path, 'wb') as f:\n","            for chunk in response.iter_content(chunk_size=8192):\n","                f.write(chunk)\n","\n","        print(f\"SUCCESS: File downloaded to {file_path}\")\n","        return file_path\n","    else:\n","        print(f\"ERROR: {response.status_code}: File may be restricted or not found\")\n","        return None\n","\n","def is_zip_file(filepath):\n","    \"\"\"\n","    Checks if a file is a valid zip file.\n","    \"\"\"\n","    try:\n","        return zipfile.is_zipfile(filepath)\n","    except:\n","        return False\n","\n","def unzip_file(filepath, extract_path=\"./\"):\n","    \"\"\"\n","    Unzips a zip file to a specified path and returns the name of the top-level extracted folder.\n","    Returns None if not a zip file or extraction fails.\n","    \"\"\"\n","    if is_zip_file(filepath):\n","        try:\n","            with zipfile.ZipFile(filepath, 'r') as zip_ref:\n","                # Get the name of the top-level directory within the zip\n","                top_level_folder = None\n","                for file_info in zip_ref.infolist():\n","                    parts = file_info.filename.split('/')\n","                    if parts[0] and len(parts) > 1:\n","                        top_level_folder = parts[0]\n","                        break\n","\n","                zip_ref.extractall(extract_path)\n","                print(f\"SUCCESS: Successfully unzipped {filepath} to {extract_path}\")\n","                return top_level_folder\n","\n","        except Exception as e:\n","            print(f\"ERROR: Error unzipping {filepath}: {e}\")\n","            return None\n","    else:\n","        print(f\"INFO: {filepath} is not a valid zip file.\")\n","        return None\n","\n","# Initialize and download the dataset\n","public_doi = \"doi:10.5683/SP3/H3HGWF\"\n","print(\"Initializing Borealis dataset access...\")\n","\n","# Get dataset information and file list\n","file_info_list = get_public_dataset_info(public_doi)\n","file_path = None\n","\n","if file_info_list:\n","    print(f\"\\nFound {len(file_info_list)} files in the dataset:\")\n","    for i, file_info in enumerate(file_info_list):\n","        print(f\"{i+1}. ID: {file_info['file_id']}, Filename: {file_info['filename']}\")\n","\n","    # Look specifically for the combined_animals.xlsx file\n","    target_file = None\n","    for file_info in file_info_list:\n","        if file_info['filename'] == 'combined_animals.xlsx':\n","            target_file = file_info\n","            break\n","\n","    if target_file:\n","        print(f\"\\nFound target file: {target_file['filename']}\")\n","\n","        # Download with the correct filename\n","        downloaded_path = download_public_file(target_file['file_id'], target_file['filename'])\n","\n","        if downloaded_path:\n","            file_path = downloaded_path\n","            print(f\"Excel file ready at: {file_path}\")\n","\n","            # Verify it's a valid Excel file\n","            try:\n","                df_test = pd.read_excel(file_path)\n","                print(f\"SUCCESS: File verified! Shape: {df_test.shape}\")\n","                print(\"Columns:\", list(df_test.columns)[:10])  # Show first 10 columns\n","                del df_test  # Clean up test dataframe\n","            except Exception as e:\n","                print(f\"WARNING: Could not read as Excel file: {e}\")\n","\n","                # Check if it might be a zip file that was misnamed\n","                if is_zip_file(file_path):\n","                    print(\"File appears to be a zip archive, extracting...\")\n","                    extracted_folder = unzip_file(file_path)\n","\n","                    if extracted_folder:\n","                        # Look for Excel files in extracted folder\n","                        for root, dirs, files in os.walk(extracted_folder):\n","                            for file in files:\n","                                if file.endswith(('.xlsx', '.xls')):\n","                                    excel_path = os.path.join(root, file)\n","                                    print(f\"Found Excel file in archive: {excel_path}\")\n","                                    file_path = excel_path\n","                                    break\n","        else:\n","            print(\"Download failed\")\n","    else:\n","        print(\"\\nTarget file 'combined_animals.xlsx' not found in dataset\")\n","        print(\"Available files:\")\n","        for file_info in file_info_list:\n","            print(f\"- {file_info['filename']}\")\n","else:\n","    print(\"Could not retrieve dataset information from Borealis\")\n","\n","# Final check and setup\n","if file_path and os.path.exists(file_path):\n","    print(f\"\\nFINAL: Dataset ready at: {file_path}\")\n","    print(\"You can now run your pandas code to load the data!\")\n","else:\n","    print(\"\\nERROR: Could not successfully download and prepare the dataset\")\n","\n","    # Show what files are actually in the directory\n","    print(\"\\nFiles currently in directory:\")\n","    for item in os.listdir('.'):\n","        if os.path.isfile(item):\n","            size = os.path.getsize(item)\n","            print(f\"- {item} ({size} bytes)\")\n","\n","print(\"\\nBorealis dataset access complete.\")"]},{"cell_type":"markdown","metadata":{"id":"FtUcuz1ws-fn"},"source":["# Volume of Sightings Across Locations Per Month"]},{"cell_type":"markdown","metadata":{"id":"d7dEJsoqzxpS"},"source":["## Module: Importing the Necessary Libraries and Loading them into a DataFrame"]},{"cell_type":"markdown","metadata":{"id":"t5gq3WTIJ9aY"},"source":["Here the `pandas` and `matplotlib.pyplot` libraries are being imported in order to use their data manipulation and visualization properties later on in the script. `pandas` will be particularly useful for transforming the data found within the given spreadsheet into an easier to manipulate DataFrame format, and `matplotlib.pyplot` is crucial for generating the graph."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lq2b6l2QGKgi"},"outputs":[],"source":["# Import necessary libraries\n","import pandas as pd\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"Otb3wT4BJ9wh"},"source":["The file path (combined_animals.xlsx) is set to the dataset retrieved via Borealis. The Excel file is then loaded into a DataFrame using `pandas`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q01bscX9GM_B"},"outputs":[],"source":["# Read the Excel file\n","file_path = 'combined_animals.xlsx'  # Change this to the correct file path if necessary\n","df = pd.read_excel(file_path)"]},{"cell_type":"markdown","metadata":{"id":"hiX59T4qJ_jE"},"source":["The `print(df.head())` code returns the first five rows of the DataFrame in order to view the contained data and ensure the file has been properly transformed into a DataFrame."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e2D9tFnjGOTb"},"outputs":[],"source":["# Check the first few rows of the DataFrame to ensure it's loaded correctly\n","print(df.head())"]},{"cell_type":"markdown","metadata":{"id":"cIexhvlfKA-o"},"source":["Here the `pd.to_datetime(df[‘Date’])` function extracts the information from the ‘Date’ column within the DataFrame and turns that data into datetime format. This conversion is critical for performing accurate time-based calculations."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PK6hyixIzaI8"},"outputs":[],"source":["# Ensure the Date column is treated as a datetime object\n","df['Date'] = pd.to_datetime(df['Date'])"]},{"cell_type":"markdown","metadata":{"id":"oQ-T9Lcucj76"},"source":["## Module: Manipulating the Dataframe"]},{"cell_type":"markdown","metadata":{"id":"s8i5c6RnKBj5"},"source":["The `.strftime(‘%B’)` method is used to specify the format of the datetime information from the 'Date' column. The `%B` code returns the full name of the month."]},{"cell_type":"markdown","metadata":{"id":"a4YUrGGzz_ZB"},"source":["`df[‘Month’]` creates a new column within the DataFrame called ‘Month’, which stores the formatted information extracted from the ‘Date’ column."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uk8w2H-YGSiT"},"outputs":[],"source":["# Extract the month from the Date column\n","df['Month'] = df['Date'].dt.strftime('%B')"]},{"cell_type":"markdown","metadata":{"id":"vA4CQpYhKCFX"},"source":["Using `df` to refer to the data stored within the DataFrame, this code accesses the information in the AdultCount and JuvenileCount columns, and uses `df[‘AdultCount’] + [‘JuvenileCount’]` to calculate the value of `df[‘TotalSightings’]`. This information is stored within the DataFrame as a new column called ‘TotalSightings’."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bg8E0TQ6GTHA"},"outputs":[],"source":["# Calculate the total number of animals spotted (AdultCount + JuvenileCount)\n","df['TotalSightings'] = df['AdultCount'] + df['JuvenileCount']"]},{"cell_type":"markdown","metadata":{"id":"Ijplnu49KCdd"},"source":["Here the DataFrame is grouped by the ‘locationID’ and ‘Month’ columns, ensuring that separate sums will be calculated for each unique combination of location ID and month. The `sum` operation is then used to calculate the sum of each ‘TotalSightings’ column per unique grouping. A new DataFrame called `aggregated_data` is then created to store the new data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bY4vRPm3GVPC"},"outputs":[],"source":["# Aggregate the data to sum the total sightings per month and location\n","aggregated_data = df.groupby(['locationID', 'Month']).agg({'TotalSightings': 'sum'}).reset_index()"]},{"cell_type":"markdown","metadata":{"id":"YwGn3cvkcqDH"},"source":["## Module: Plotting the Bar Graph"]},{"cell_type":"markdown","metadata":{"id":"Y36NMjs6KC2d"},"source":["This code begins by creating an empty figure and set of subplots, `fig, ax`, while `figsize=(14, 8)` sets the dimensions of the figure in inches.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_kOneK7__DxD"},"source":["Then the code retrieves all of the unique month values from the DataFrame. The `for month in aggregated_data[‘Month’].unique():` iterates over each unique month, while `subset = aggregated_data[aggregated_data[‘Month’] == month]` filters the information so that only rows matching the current month of the loop is included in the creation of that month’s subset."]},{"cell_type":"markdown","metadata":{"id":"eWgJFICt0mp3"},"source":["`ax.bar()` creates a bar plot for the given subset, and the x-axis values and height of the bars are set as ‘locationID’ and ‘TotalSightings’ respectively."]},{"cell_type":"markdown","metadata":{"id":"ziD8pA_j_G5h"},"source":["Next labels are assigned to the x and y axes, and a title is provided for the entire graph. `ax.legend(title=’Month’)` generates a title for the legend."]},{"cell_type":"markdown","metadata":{"id":"W2GgiOFJ0smW"},"source":["Finally, the graph is visualized using `plt.show()`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PLchzK4ZGXo8"},"outputs":[],"source":["# Generate a bar plot\n","fig, ax = plt.subplots(figsize=(14, 8))\n","\n","# Create a bar plot for each month and location ID\n","for month in aggregated_data['Month'].unique():\n","    subset = aggregated_data[aggregated_data['Month'] == month]\n","    ax.bar(subset['locationID'], subset['TotalSightings'], label=month)\n","\n","# Set the labels and title\n","ax.set_xlabel('Location ID')\n","ax.set_ylabel('Number of Sightings')\n","ax.set_title('Volume of Species Sightings by Location ID and Month')\n","ax.legend(title='Month')\n","\n","ax.set_xticks(aggregated_data['locationID'].unique())\n","ax.set_xticklabels(aggregated_data['locationID'].unique(), rotation=90)\n","\n","plt.xticks(rotation=90)\n","\n","# Display the plot\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Gsa4mCvscMfR"},"source":["# Volume of Sightings Across Locations Per Season"]},{"cell_type":"markdown","metadata":{"id":"8HcebYpXAug3"},"source":["In order to create a bar graph depicting the volume of sightings across locations by season, the first few blocks of code will remain the same as in the previous script."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ynP7Kfb2AJVA"},"outputs":[],"source":["# Import necessary libraries\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Read the Excel file\n","file_path = './combined_animals.xlsx'\n","df = pd.read_excel(file_path)\n","\n","# Ensure the Date column is treated as a datetime object\n","df['Date'] = pd.to_datetime(df['Date'])\n","\n","# Extract the month from the Date column\n","df['Month'] = df['Date'].dt.month"]},{"cell_type":"markdown","metadata":{"id":"T60HRxJspa-r"},"source":["## Module: Manipulating the Dataframe"]},{"cell_type":"markdown","metadata":{"id":"OrVOqAVP07uY"},"source":["A dictionary is created and assigned to the `month_to_season` variable. The dictionary stores the months of the year in integer format and their corresponding seasons."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LHgC3b0aAMFa"},"outputs":[],"source":["# Map the months to seasons\n","month_to_season = {3: 'Spring', 4: 'Spring', 5: 'Spring',\n","                   6: 'Summer', 7: 'Summer', 8: 'Summer',\n","                   9: 'Autumn', 10: 'Autumn', 11: 'Autumn',\n","                   12: 'Winter', 1: 'Winter', 2: 'Winter'}"]},{"cell_type":"markdown","metadata":{"id":"EkkIf8sSAvVl"},"source":["A new column is created in the DataFrame called ‘Season’ and the script populates the column with the corresponding value for each month in the ‘Month’ column of the DataFrame."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oixixx3dAN7X"},"outputs":[],"source":["df['Season'] = df['Month'].map(month_to_season)"]},{"cell_type":"markdown","metadata":{"id":"T-JSAEtCAvxC"},"source":["Before calculating totals, missing values in `AdultCount` and `JuvenileCount` are filled with zero to ensure accurate aggregation. The calculation of the ‘TotalSightings’ variable, creation of the `aggregated_data` DataFrame, and figure generation are all the same as the previous bar graph script."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"huqTeL4fmAPK"},"outputs":[],"source":["# Fill NaN values with 0 for count columns\n","df['AdultCount'] = df['AdultCount'].fillna(0)\n","df['JuvenileCount'] = df['JuvenileCount'].fillna(0)\n","\n","# Calculate the total number of animals spotted (AdultCount + JuvenileCount)\n","df['TotalSightings'] = df['AdultCount'] + df['JuvenileCount']\n","\n","# Aggregate the data to sum the total sightings per month and location\n","aggregated_data = df.groupby(['locationID', 'Season']).agg({'TotalSightings': 'sum'}).reset_index()\n","\n","# Generate a bar plot\n","fig, ax = plt.subplots(figsize=(14, 8))\n","\n","# Get the colormap\n","color_map = plt.get_cmap('tab20c')\n","\n","# Map each season to a color from the colormap\n","season_to_color = {'Spring': color_map(0), 'Summer': color_map(4), 'Autumn': color_map(8), 'Winter': color_map(12)}\n","\n","# Create a bar plot for each season and location ID\n","for season in aggregated_data['Season'].unique():\n","    subset = aggregated_data[aggregated_data['Season'] == season]\n","    ax.bar(subset['locationID'], subset['TotalSightings'], label=season, color=season_to_color[season])\n","\n","ax.set_xticks(aggregated_data['locationID'].unique())\n","ax.set_xticklabels(aggregated_data['locationID'].unique(), rotation=90)\n","\n","# Set the labels and title\n","ax.set_xlabel('Location ID')\n","ax.set_ylabel('Number of Sightings')\n","ax.set_title('Volume of Species Sightings by Location ID and Season')\n","ax.legend(title='Season')\n","\n","# Make sure all X labels are displayed\n","plt.xticks(rotation=90)\n","\n","# Display the plot\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"VIAa_p-8soef"},"source":["## Module: Plotting the Graph"]},{"cell_type":"markdown","metadata":{"id":"sOHAoGkBm_GJ"},"source":["Here the `plt.get_cmap()` function is used to import the ‘tab20c’ color map. Colors from the imported color map are then assigned to each season."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0rWbWU0RmDwH"},"outputs":[],"source":["# Get the colormap\n","color_map = plt.get_cmap('tab20c')\n","\n","# Map each season to a color from the colormap\n","season_to_color = {'Spring': color_map(0), 'Summer': color_map(4), 'Autumn': color_map(8), 'Winter': color_map(12)}"]},{"cell_type":"markdown","metadata":{"id":"fW_rrzmvoe46"},"source":["The season information within the `aggregated_data` DataFrame is iterated over and filtered, just as the month data was in the previous script. The x-axis values, bar heights, and labels are also determined in the same way."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XtsVp0sgmnmz"},"outputs":[],"source":["# Create a bar plot for each season and location ID\n","for season in aggregated_data['Season'].unique():\n","    subset = aggregated_data[aggregated_data['Season'] == season]\n","    ax.bar(subset['locationID'], subset['TotalSightings'], label=season, color=season_to_color[season])"]},{"cell_type":"markdown","metadata":{"id":"ub-7WTxAp2kV"},"source":["This code block simply formats the x-ticks and x-tick labels appropriately for the graph. `rotation=90` rotates the x-tick labels by 90 degrees to maintain legibility.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gwCztxSNmoSW"},"outputs":[],"source":["ax.set_xticks(aggregated_data['locationID'].unique())\n","ax.set_xticklabels(aggregated_data['locationID'].unique(), rotation=90)"]},{"cell_type":"markdown","metadata":{"id":"jY4L9WILp27h"},"source":["Here the labels for each axis are set, as well as the title for the overall graph. `plt.xticks(rotation=90)` ensures that all of the x-tick labels will be displayed, and the plot is visualized using `plt.show()`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EdUHEp6fATgA"},"outputs":[],"source":["# Create a new figure and axis for the seasonal plot\n","fig, ax = plt.subplots(figsize=(14, 8))\n","\n","# Create a bar plot for each season and location ID\n","for season in aggregated_data['Season'].unique():\n","    subset = aggregated_data[aggregated_data['Season'] == season]\n","    ax.bar(subset['locationID'], subset['TotalSightings'],\n","           label=season, color=season_to_color[season])\n","\n","# Set the labels and title\n","ax.set_xlabel('Location ID')\n","ax.set_ylabel('Number of Sightings')\n","ax.set_title('Volume of Species Sightings by Location ID and Season')\n","ax.legend(title='Season')\n","\n","# Ensure all X labels are shown\n","ax.set_xticks(aggregated_data['locationID'].unique())\n","ax.set_xticklabels(aggregated_data['locationID'].unique(), rotation=90)\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"7cGGIWhN3gtY"},"source":["# Volume of Sightings Across Locations Per Species"]},{"cell_type":"markdown","metadata":{"id":"qUMAlB6Bt8aQ"},"source":["In order to plot a bar graph to depict the volume of sightings per species across locations, the same libraries must be imported with the addition of the `numpy` library. The `numpy` library is crucial for working with arrays and large data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RYCgqUGNtHc9"},"outputs":[],"source":["# Import necessary libraries\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"gn2OL7AnuCOx"},"source":["Just like the previous two scripts, the Excel sheet must be converted into a two-dimensional DataFrame before any data manipulation can take place.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cu-tQrOAtL3d"},"outputs":[],"source":["# Read the Excel file\n","file_path = './combined_animals.xlsx'  # Change this to the correct file path if necessary\n","df = pd.read_excel(file_path)"]},{"cell_type":"markdown","metadata":{"id":"EQHsSZBewv0_"},"source":["## Module: Manipulating the Dataframe"]},{"cell_type":"markdown","metadata":{"id":"UM_FDD-EuLrA"},"source":["The species information does not need to be converted into any other formats before the graph is generated, so the manipulation of the DataFrame will be much simpler for this script."]},{"cell_type":"markdown","metadata":{"id":"WAZkWGdx1iGK"},"source":["The ‘TotalSightings’ column will be added to the DataFrame after the values from the ‘AdultCount’ and ‘JuvenileCount’ columns have been added together. Then the rows will be grouped by locationID and SpeciesList, creating a new DataFrame called `aggregated_data`. The number of unique species is determined using `.nunique()`, which is then used to evenly assign colors from the colormap."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7AYdWrXBtMjc"},"outputs":[],"source":["# Ensure the Date column is treated as a datetime object\n","df['Date'] = pd.to_datetime(df['Date'])\n","\n","# Calculate the total number of animals spotted (AdultCount + JuvenileCount)\n","df['TotalSightings'] = df['AdultCount'] + df['JuvenileCount']\n","\n","# Aggregate the data to sum the total sightings per species and location\n","aggregated_data = df.groupby(['locationID', 'SpeciesList']).agg({'TotalSightings': 'sum'}).reset_index()\n","\n","# Determine the number of unique species (needed for colors)\n","num_categories = len(aggregated_data['SpeciesList'].unique())"]},{"cell_type":"markdown","metadata":{"id":"EgtKrdeGw2qO"},"source":["## Module: Plotting the Graph"]},{"cell_type":"markdown","metadata":{"id":"bMxlgcY4vUvq"},"source":["The tab20c colormap is imported using the `plt.get_cmap()` function, and `np.linspace(0, 1, num_categories)` creates an equally spaced list of `num_categories` between 0 and 1 in order to evenly spread the colors selected for each species. A dictionary called `species_to_color` is then created to map a color to each species. The final code block ensures that there is a bar plot for each individual species. The graph is plotted in the same way as the previous two scripts, with a small difference to ensure the legend does not clip the graph. `plt.tight_layout(rect=[0, 0, 0.85, 1])` ensures that there is enough space left for the legend."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5edhooKdtPLk"},"outputs":[],"source":["# Set up the figure and axis for plotting\n","fig, ax = plt.subplots(figsize=(14, 8))\n","\n","# Create color map\n","colors = plt.get_cmap('tab20c')(np.linspace(0, 1, num_categories))\n","\n","# Generate a mapping of SpeciesList to colors\n","species_to_color = {\n","    species: colors[i]\n","    for i, species in enumerate(sorted(aggregated_data['SpeciesList'].unique()))\n","}\n","\n","# Iterate over each species to plot\n","for species, group in aggregated_data.groupby('SpeciesList'):\n","    ax.bar(group['locationID'], group['TotalSightings'],\n","           label=species, color=species_to_color[species])\n","\n","# Set the labels and title\n","ax.set_xlabel('Location ID')\n","ax.set_ylabel('Number of Sightings')\n","ax.set_title('Volume of Species Sightings by Location ID and Species')\n","ax.legend(title='Species', bbox_to_anchor=(1.05, 1), loc='upper left')\n","\n","# Ensure x-axis shows every location ID\n","ax.set_xticks(aggregated_data['locationID'].unique())\n","ax.set_xticklabels(aggregated_data['locationID'].unique(), rotation=90)\n","\n","# Improve layout and avoid clipping\n","plt.tight_layout(rect=[0, 0, 0.85, 1])\n","plt.show()\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}