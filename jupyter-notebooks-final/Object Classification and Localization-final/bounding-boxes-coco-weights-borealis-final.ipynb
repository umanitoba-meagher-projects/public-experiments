{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0063121a-197c-4b0d-8e55-5159458e5fbe"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Author: Mitch Constable & A.V. Ronquillo\n",
        "Date: May 17, 2024\n",
        "\n",
        "Purpose: To create bounding boxes using resnet50 on dataset\n",
        "of animal images.\n",
        "\n",
        "Note: The author generated this text in part with GPT-4,\n",
        "OpenAI‚Äôs large-scale language-generation model. Upon generating\n",
        "draft code, the author reviewed, edited, and revised the code\n",
        "to their own liking and takes ultimate responsibility for\n",
        "the content of this code.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f089e5bb"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This notebook uses a pre-trained Faster R-CNN model to automatically detect and locate objects in 100 deer images by generating bounding boxes with confidence scores. The workflow loads the model, processes images, runs inference, and filters results based on a configurable confidence threshold before saving annotated outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea09d2b1"
      },
      "source": [
        "# Critical Uses & Adaptability\n",
        "\n",
        "## What the Notebook Can Be Used For:\n",
        "\n",
        "- **Dataset Exploration:** The notebook enables exploration of image datasets by automatically detecting and highlighting objects of interest. This is useful for quickly assessing the content and quality of a dataset, identifying labeling inconsistencies, or verifying the presence of target objects (in our case urban animals).\n",
        "\n",
        "- **Educational Purposes & Demonstrations:** The notebook shows how Python code, scripting, and machine learning models can be applied to image-based tasks. By extracting bounding box coordinates, class labels, and confidence scores, the structured data can be used for further analysis such as statistical summaries, dataset curation, or as input features for other machine learning models.\n",
        "\n",
        "## How the Notebook Can Be Adapted:\n",
        "\n",
        "- **Integration with Spatial Design:** The methodology can be extended to site analysis or spatial design projects by applying object detection to images of built environments, landscapes, or architectural sites. Detected features can inform spatial mapping, usage studies, or environmental assessments.\n",
        "\n",
        "- **Variables & Customization:** Variables like `confidence_threshold` (see Cell 7) and `image_dir` (see Cell 6) can be adjusted to refine detection sensitivity or to point to different image sources. By changing the `image_dir` variable in the code block in Cell 6 you can process any directory of images.\n",
        "\n",
        "- **Different Data Sources:** The Borealis API functions can be modified to work with other data repositories, or the image directory detection can be pointed to local or cloud storage locations.\n",
        "\n",
        "- **Extended Analysis:** The detection results can be exported to CSV or JSON formats for further statistical analysis, or integrated with spatial analysis tools for geographic applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_KLvbVtDwzF"
      },
      "source": [
        "## Importing Essential Libraries & Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuMuFLQID-xr"
      },
      "source": [
        "This module imports all essential libraries for the complete pipeline. The key addition is the proper `FasterRCNN_ResNet50_FPN_Weights` import which fixes the deprecated `pretrained=True parameter` issue. This environment setup will also include the import of `math` for advanced visualization layouts and `shutil` for file operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Gc2kj0LQEWer"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights\n",
        "from torchvision.transforms import functional as F\n",
        "from PIL import Image\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import requests\n",
        "import zipfile\n",
        "import shutil\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk9yXVdiESGI"
      },
      "source": [
        "## Borealis API Configuration & Source Dataset Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InGWG0sCEiGg"
      },
      "source": [
        "The data is hosted in the University of Manitoba Dataverse (https://borealisdata.ca/dataverse/manitoba), a research data repository. The images used in this notebook were collected as part of the 'Understanding Animals' project at University of Manitoba Faculty of Architecture, online at [Wild Winnipeg](https://www.wildwinnipeg.org/) and [Teaching with Images](https://pressbooks.openedmb.ca/teachingwithimages/). These functions handle the automatic downloading of datasets from the Borealis repository. The `get_public_dataset_info()` function retrieves metadata about available files, while `download_public_file()` handles the actual file download with proper error handling and progress feedback."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjuaWc4qB95J"
      },
      "outputs": [],
      "source": [
        "# Borealis API configuration\n",
        "BOREALIS_SERVER = \"https://borealisdata.ca\"\n",
        "\n",
        "def get_public_dataset_info(persistent_id):\n",
        "    \"\"\"\n",
        "    Get information about a public dataset\n",
        "    \"\"\"\n",
        "    url = f\"{BOREALIS_SERVER}/api/datasets/:persistentId/\"\n",
        "    params = {\"persistentId\": persistent_id}\n",
        "\n",
        "    response = requests.get(url, params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        dataset_info = response.json()\n",
        "    else:\n",
        "        print(f\"Cannot access dataset: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "    # Get a list of files in a public dataset\n",
        "    files_list = dataset_info['data']['latestVersion']['files']\n",
        "    file_info_list = []\n",
        "\n",
        "    for file_info in files_list:\n",
        "        file_id = file_info['dataFile']['id']\n",
        "        filename = file_info['dataFile']['filename']\n",
        "        file_info_list.append({\"file_id\": file_id, \"filename\": filename})\n",
        "\n",
        "    return file_info_list\n",
        "\n",
        "def download_public_file(file_id, save_path=\"./\"):\n",
        "    \"\"\"\n",
        "    Download a specific public file from a dataset by its file ID\n",
        "    \"\"\"\n",
        "    url = f\"{BOREALIS_SERVER}/api/access/datafile/{file_id}\"\n",
        "    response = requests.get(url, stream=True)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        filename = None\n",
        "        if \"Content-Disposition\" in response.headers:\n",
        "            cd = response.headers[\"Content-Disposition\"]\n",
        "            if \"filename=\" in cd:\n",
        "                filename = cd.split(\"filename=\")[1].strip('\"')\n",
        "\n",
        "        if not filename:\n",
        "            filename = url.split(\"/\")[-1]\n",
        "\n",
        "        file_path = os.path.join(save_path, filename)\n",
        "\n",
        "        with open(file_path, 'wb') as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "\n",
        "        print(f\"SUCCESS: File downloaded to {file_path}\")\n",
        "        return file_path\n",
        "    else:\n",
        "        print(f\"ERROR: {response.status_code}: File may be restricted or not found\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eypu9AHmEqjg"
      },
      "source": [
        "## File Extraction & Directory Management"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Xrz1xcAEvXI"
      },
      "source": [
        "This module provides robust file handling capabilities. The `unzip_file()` function safely extracts ZIP archives, while `find_image_directory()` intelligently searches through the extracted contents to locate the directory containing image files. This eliminates the need for manual path specification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVTz_9BnE2XB"
      },
      "outputs": [],
      "source": [
        "def is_zip_file(filepath):\n",
        "    \"\"\"\n",
        "    Checks if a file is a valid zip file.\n",
        "    \"\"\"\n",
        "    return zipfile.is_zipfile(filepath)\n",
        "\n",
        "def unzip_file(filepath, extract_path=\"./\"):\n",
        "    \"\"\"\n",
        "    Unzips a zip file to a specified path\n",
        "    \"\"\"\n",
        "    if is_zip_file(filepath):\n",
        "        try:\n",
        "            with zipfile.ZipFile(filepath, 'r') as zip_ref:\n",
        "                zip_ref.extractall(extract_path)\n",
        "                print(f\"SUCCESS: Successfully unzipped {filepath} to {extract_path}\")\n",
        "\n",
        "                # List extracted contents\n",
        "                extracted_files = zip_ref.namelist()\n",
        "                print(f\"Extracted {len(extracted_files)} files\")\n",
        "                return True\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR: Error unzipping {filepath}: {e}\")\n",
        "            return False\n",
        "    else:\n",
        "        print(f\"INFO: {filepath} is not a valid zip file.\")\n",
        "        return False\n",
        "\n",
        "def find_image_directory():\n",
        "    \"\"\"\n",
        "    Find where the images were extracted\n",
        "    \"\"\"\n",
        "    # Look for common patterns\n",
        "    possible_dirs = []\n",
        "\n",
        "    # Check current directory for any folders containing images\n",
        "    for item in os.listdir('.'):\n",
        "        if os.path.isdir(item):\n",
        "            # Check if this directory contains JPG files\n",
        "            jpg_files = glob.glob(os.path.join(item, '**/*.JPG'), recursive=True)\n",
        "            if jpg_files:\n",
        "                possible_dirs.append((item, len(jpg_files)))\n",
        "\n",
        "    if possible_dirs:\n",
        "        # Sort by number of JPG files found\n",
        "        possible_dirs.sort(key=lambda x: x[1], reverse=True)\n",
        "        best_dir = possible_dirs[0][0]\n",
        "\n",
        "        # Find the actual subdirectory with images\n",
        "        for root, dirs, files in os.walk(best_dir):\n",
        "            jpg_files = [f for f in files if f.endswith('.JPG')]\n",
        "            if jpg_files:\n",
        "                print(f\"üìÅ Found {len(jpg_files)} images in: {root}\")\n",
        "                return root\n",
        "\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlZKzw_zE5CQ"
      },
      "source": [
        "## Output Folder Creation & Organization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a59myiliE9xH"
      },
      "source": [
        "This short module creates a structured output directory system. The main `animal_detection_results` folder contains a subfolder for `annotated_images`, providing clear organization of results. The `exist_ok=True` parameter prevents errors if directories already exist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yThqnyAUFGxo"
      },
      "outputs": [],
      "source": [
        "def create_output_folders():\n",
        "    \"\"\"\n",
        "    Create organized output folders\n",
        "    \"\"\"\n",
        "    # Create main output directory\n",
        "    output_dir = \"animal_detection_results\"\n",
        "    annotated_dir = os.path.join(output_dir, \"annotated_images\")\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    os.makedirs(annotated_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"‚úÖ Created output directory: {output_dir}\")\n",
        "    print(f\"‚úÖ Created annotated images directory: {annotated_dir}\")\n",
        "\n",
        "    return output_dir, annotated_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuJfmaCaFIgq"
      },
      "source": [
        "## Load the Model with Proper COCO Weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsaot2OYFOtv"
      },
      "source": [
        "In this critical module, instead of using the deprecated `pretrained=True parameter`, the `weights=FasterRCNN_ResNet50_FPN_Weights` will now be integrated into the notebook script. Then, the `COCO_V1` properly loads the COCO-trained weights. The model is set to evaluation mode for inference, and output directories are created immediately after model loading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vG0FWnAFtdv"
      },
      "outputs": [],
      "source": [
        "# Load the pretrained model with proper weights parameter\n",
        "print(\"üì• Loading pre-trained model...\")\n",
        "model = fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1)\n",
        "model = model.eval()\n",
        "print(\"‚úÖ Model loaded successfully\")\n",
        "\n",
        "# Create output directories\n",
        "output_dir, annotated_dir = create_output_folders()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0ZxcK0eFu0W"
      },
      "source": [
        "## Dataset Download & Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQP7KL0-F0Gv"
      },
      "source": [
        "This module handles the complete dataset acquisition process. It connects to the Borealis repository using the specified DOI, downloads the ZIP file containing the animal images, extracts it, and then intelligently locates the directory containing the actual image files. The robust error handling ensures the process fails gracefully if any step encounters issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17pMW9dYFxMn"
      },
      "outputs": [],
      "source": [
        "# Download and extract dataset\n",
        "print(\"\\nüì¶ Downloading dataset from Borealis...\")\n",
        "public_doi = \"doi:10.5683/SP3/H3HGWF\"\n",
        "dataset_files = get_public_dataset_info(public_doi)\n",
        "\n",
        "if dataset_files:\n",
        "    for file_info in dataset_files:\n",
        "        if file_info['filename'].endswith('.zip'):\n",
        "            print(f\"üì• Downloading {file_info['filename']}...\")\n",
        "            downloaded_zip = download_public_file(file_info['file_id'])\n",
        "            if downloaded_zip:\n",
        "                print(\"üìÇ Extracting files...\")\n",
        "                unzip_file(downloaded_zip, \"./\")\n",
        "            break\n",
        "\n",
        "# Find where images are located\n",
        "print(\"\\nüîç Locating image files...\")\n",
        "image_directory = find_image_directory()\n",
        "\n",
        "if not image_directory:\n",
        "    print(\"‚ùå ERROR: Could not find image directory\")\n",
        "    print(\"Current directory contents:\")\n",
        "    for item in os.listdir('.'):\n",
        "        print(f\"  {item}\")\n",
        "    exit()\n",
        "\n",
        "print(f\"‚úÖ Found image directory: {image_directory}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEOqba8LF37S"
      },
      "source": [
        "## Image Processing Configuration & Detection Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjn-AKIFF76t"
      },
      "source": [
        "This is the core processing loop that handles each image individually. For each image, it loads and converts it to RGB format, applies the `transform` to create a `tensor`, runs inference through the model, and processes the results. The `confidence_threshold` of `0.5` filters out low-confidence detections. For valid detections, it draws red bounding boxes and adds labels with confidence scores. Each annotated image is saved to the organized output directory with detailed progress reporting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypFWufHKGUpv"
      },
      "outputs": [],
      "source": [
        "# Process images\n",
        "print(f\"\\nüéØ Processing images from: {image_directory}\")\n",
        "print(f\"üìÅ Saving results to: {annotated_dir}\")\n",
        "\n",
        "# Set confidence threshold for detection\n",
        "confidence_threshold = 0.5\n",
        "transform = F.to_tensor\n",
        "\n",
        "# Find all JPG files\n",
        "image_files = glob.glob(os.path.join(image_directory, '*.JPG'))\n",
        "print(f\"üì∑ Found {len(image_files)} images to process\")\n",
        "\n",
        "if not image_files:\n",
        "    print(\"‚ùå No JPG files found!\")\n",
        "    exit()\n",
        "\n",
        "# Process each image\n",
        "annotated_count = 0\n",
        "detected_count = 0\n",
        "\n",
        "for i, image_path in enumerate(image_files, 1):\n",
        "    print(f\"\\n[{i}/{len(image_files)}] Processing: {os.path.basename(image_path)}\")\n",
        "\n",
        "    try:\n",
        "        # Load and process image\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        image_tensor = transform(image)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            prediction = model([image_tensor])\n",
        "\n",
        "        boxes = prediction[0]['boxes']\n",
        "        scores = prediction[0]['scores']\n",
        "        labels = prediction[0]['labels']\n",
        "\n",
        "        # Create figure\n",
        "        fig, ax = plt.subplots(1, figsize=(12, 8))\n",
        "        ax.imshow(image)\n",
        "        ax.set_title(f'Detected Objects: {os.path.basename(image_path)}', fontsize=14)\n",
        "\n",
        "        # Count detections above threshold\n",
        "        detections_in_image = 0\n",
        "\n",
        "        for box, score, label in zip(boxes, scores, labels):\n",
        "            if score > confidence_threshold:\n",
        "                detections_in_image += 1\n",
        "                print(f\"  üéØ Detection: Label {label.item()}, Score: {score.item():.3f}\")\n",
        "\n",
        "                # Draw bounding box\n",
        "                x, y, xmax, ymax = box\n",
        "                rect = patches.Rectangle((x, y), (xmax - x), (ymax - y),\n",
        "                                       linewidth=2, edgecolor='red', facecolor='none')\n",
        "                ax.add_patch(rect)\n",
        "\n",
        "                # Add label text\n",
        "                ax.text(x, y-5, f'Label: {label.item()}\\nScore: {score.item():.2f}',\n",
        "                       bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7),\n",
        "                       fontsize=8)\n",
        "\n",
        "        if detections_in_image > 0:\n",
        "            detected_count += 1\n",
        "            print(f\"  ‚úÖ Found {detections_in_image} objects above threshold\")\n",
        "        else:\n",
        "            print(f\"  ‚ö™ No objects detected above threshold\")\n",
        "\n",
        "        # Save annotated image\n",
        "        image_name = os.path.basename(image_path)\n",
        "        save_path = os.path.join(annotated_dir, f'annotated_{image_name}')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        annotated_count += 1\n",
        "        print(f\"  üíæ Saved: annotated_{image_name}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ùå Error processing {image_path}: {e}\")\n",
        "        continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5ZByJ9OGYm8"
      },
      "source": [
        "## Print Processing Results & Display Annotated Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMNfrVqyGisV"
      },
      "source": [
        "This final module provides comprehensive results analysis and visualization. It calculates and displays summary statistics including processing success rates and detection rates. The advanced visualization system creates a grid layout displaying all annotated images simultaneously, with 5 images per row for optimal viewing. The grid automatically adjusts for different numbers of images and handles edge cases gracefully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D028DtbLGX4X"
      },
      "outputs": [],
      "source": [
        "# Final summary\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"üéâ PROCESSING COMPLETE!\")\n",
        "print(f\"üìä Summary:\")\n",
        "print(f\"   ‚Ä¢ Total images processed: {annotated_count}\")\n",
        "print(f\"   ‚Ä¢ Images with detections: {detected_count}\")\n",
        "print(f\"   ‚Ä¢ Detection rate: {(detected_count/annotated_count*100):.1f}%\" if annotated_count > 0 else \"   ‚Ä¢ No images processed\")\n",
        "print(f\"   ‚Ä¢ Results saved in: {annotated_dir}\")\n",
        "print(f\"   ‚Ä¢ Total files in output folder: {len(os.listdir(annotated_dir))}\")\n",
        "\n",
        "# List some example output files\n",
        "output_files = os.listdir(annotated_dir)\n",
        "if output_files:\n",
        "    print(f\"\\nüìÅ Example output files:\")\n",
        "    for i, filename in enumerate(output_files[:5]):\n",
        "        print(f\"   {i+1}. {filename}\")\n",
        "    if len(output_files) > 5:\n",
        "        print(f\"   ... and {len(output_files) - 5} more files\")\n",
        "\n",
        "# Display annotated images\n",
        "print(f\"\\nüñºÔ∏è Displaying all {len(output_files)} annotated images...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Display all annotated images in a grid\n",
        "if output_files:\n",
        "    # Set fixed grid: 5 images per row for better visibility\n",
        "    num_images = len(output_files)\n",
        "    cols = 5  # Fixed at 5 columns\n",
        "    rows = math.ceil(num_images / cols)\n",
        "\n",
        "    # Create a large figure with bigger images (6 inches per image width, 4 inches height)\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 6, rows * 4))\n",
        "    fig.suptitle(f'All {num_images} Annotated Images - Animal Detection Results (5 per row)', fontsize=20, y=0.98)\n",
        "\n",
        "    # Handle case where we have only one row or column\n",
        "    if rows == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "    elif cols == 1:\n",
        "        axes = axes.reshape(-1, 1)\n",
        "\n",
        "    # Display each image\n",
        "    for idx, filename in enumerate(sorted(output_files)):\n",
        "        row = idx // cols\n",
        "        col = idx % cols\n",
        "\n",
        "        try:\n",
        "            img_path = os.path.join(annotated_dir, filename)\n",
        "            img = Image.open(img_path)\n",
        "\n",
        "            axes[row, col].imshow(img)\n",
        "            axes[row, col].set_title(filename.replace('annotated_', '').replace('.JPG', ''), fontsize=10)\n",
        "            axes[row, col].axis('off')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {filename}: {e}\")\n",
        "            axes[row, col].set_title(f\"Error: {filename}\", fontsize=10)\n",
        "            axes[row, col].axis('off')\n",
        "\n",
        "    # Hide any unused subplots\n",
        "    for idx in range(num_images, rows * cols):\n",
        "        row = idx // cols\n",
        "        col = idx % cols\n",
        "        axes[row, col].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.95)\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"‚úÖ Successfully displayed all {num_images} annotated images!\")\n",
        "else:\n",
        "    print(\"‚ùå No annotated images found to display.\")\n",
        "\n",
        "print(f\"\\n‚úÖ All done! Check the '{output_dir}' folder in your file browser.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
