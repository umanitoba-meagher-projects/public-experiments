{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/mmeagher/experiments/blob/main/jupyter-notebooks/Visualize%20Image%20Information/close-encounters-network.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DrqG_YLiY1Ky"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Ryleigh J. Bruce\n",
    "Date: June 28, 2024\n",
    "\n",
    "Purpose: To extract data regarding close encounters between different animal species and store the data in an Excel sheet, which can then be used to generate a plot to visualize the key data.\n",
    "\n",
    "\n",
    "Note: The author generated this text in part with GPT-4,\n",
    "OpenAI’s large-scale language-generation model. Upon generating\n",
    "draft code, the authors reviewed, edited, and revised the code\n",
    "to their own liking and takes ultimate responsibility for\n",
    "the content of this code.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This Jupyter Notebook is designed to analyze and visualize close encounters between different animal species using a structured dataset. The primary purpose of the notebook is to extract, process, and represent data regarding interspecies and intraspecies interactions, specifically focusing on encounters occurring within defined spatial and temporal parameters. The notebook performs several tasks, including data extraction from Excel files, manipulation of dataframes, grouping of observations into sequences, and identification of close encounters based on time and location. It then generates a network graph that visually maps these interactions, using nodes to represent species and edges to represent encounters. The methodology involves leveraging Python libraries such as Pandas for data manipulation, Matplotlib for visualization, and NetworkX for graph construction. Additionally, the notebook incorporates image processing to include species silhouettes in the graph. The benefits of this notebook include its ability to provide a clear and structured representation of animal interactions, its adaptability to different datasets, and its utility in both research and educational contexts. By automating the analysis and visualization process, the notebook offers a streamlined approach to understanding complex ecological data.\n",
    "\n",
    "## Critical Uses & Adaptability\n",
    "\n",
    "### What the Notebook Can Be Used For:\n",
    "- **Dataset Exploration:** \n",
    "This notebook is particularly useful for exploring datasets that involve temporal and spatial observations. By grouping data into sequences and identifying patterns of interaction, it allows users to uncover insights about animal behavior and movement. The sorting and grouping operations in cells such as `# Group the data into sequences` and `# Process each locationID` facilitate efficient exploration of large datasets.\n",
    "\n",
    "- **Educational Purposes & Demonstrations:**\n",
    "The notebook serves as a practical example of how Python can be used for data analysis and visualization. It demonstrates the integration of libraries like Pandas, Matplotlib, and NetworkX to process and visualize data. Additionally, it educates users on how to work with machine learning-adjacent tasks, such as feature extraction and image processing, as seen in the `get_image()` function and the use of silhouette images.\n",
    "\n",
    "- **Feature Extraction:**\n",
    "The notebook extracts meaningful features from raw data, such as the number of encounters, time differences, and species interactions. These features are then used to create a network graph that highlights relationships and patterns. The `group_sequences()` function and the edge-weighting logic in `# Build the graph and assign colors` are key examples of feature extraction in action.\n",
    "\n",
    "### How the Notebook Can Be Adapted:\n",
    "\n",
    "- **Integration with Spatial Design & Architectural Studies:**\n",
    "The notebook can be adapted for spatial design and architectural studies by analyzing site-specific data. For example, the `locationID` variable can be used to represent different areas within a site, enabling site analysis and spatial interaction mapping. This could be applied to urban planning or ecological site assessments.\n",
    "\n",
    "- **Variables & Customization:**\n",
    "The notebook's variables, such as `time_diff` and `locationID`, can be adjusted to suit different datasets or research questions. For instance, the time threshold for defining close encounters can be modified in the `# Process each locationID` block to analyze interactions over different time scales.\n",
    "\n",
    "- **Swapping Datasets:**\n",
    "The notebook is designed to work with custom datasets. To use a different dataset, users can modify the file paths in the `# File paths` block, such as `file_path` and `output_file_path`. The structure of the dataset should align with the expected columns, but minor adjustments can be made to the data processing steps to accommodate variations.\n",
    "\n",
    "- **Scalability:**\n",
    "The notebook can be scaled to handle larger datasets or more complex analyses. For example, additional features such as species density or environmental factors can be incorporated into the analysis. The modular structure of the code, with functions like `group_sequences()` and `draw_curved_edges()`, makes it easy to extend the notebook's functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yaEpDyUIY4AS"
   },
   "source": [
    "## Module: Mount the Notebook to Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXbCeGMYY41A"
   },
   "source": [
    "Here we import the drive module that allows us to link the Colab environment with our google drive, where the desired data set is stored. This allows us to access any files located within Google Drive and interact with them directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 840,
     "status": "ok",
     "timestamp": 1721670220269,
     "user": {
      "displayName": "Ryleigh Bruce",
      "userId": "04866625339349492872"
     },
     "user_tz": 300
    },
    "id": "yJzvyyX-6yqE",
    "outputId": "ec5dd32b-f1cb-41f4-8089-154943a12e1c"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8ddXiaw7Ihy"
   },
   "source": [
    "# Organizing Species Observations into Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__dRXw6SIlHc"
   },
   "source": [
    "Please note that the following sequencing script was originally run in VS Code due to the high runtime required to run the script in Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLUYt1kFIfjI"
   },
   "source": [
    "## Module: Importing the Necessary Libaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ioHNgM6tKc7f"
   },
   "source": [
    "In order to run the script the `Pandas` library and `timedelta` class from the `datetime` module must be imported. These will be critical for data analysis and manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2wZeUBj5KnW1"
   },
   "source": [
    "The `timedelta` class is used to represent a duration, such as the difference between two times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S7y8DVUg8xta"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2n1NVqn3KtJK"
   },
   "source": [
    "## Module: Reading the Excel File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AvMAUd4EMesP"
   },
   "source": [
    "Here the file paths for the source data file and the Excel file that will be generated are defined. If the name of the new file being created should be changed, simply update `sequenced_sightingas_data.xlsx` to the desired file name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1IU_8K7Mh1d"
   },
   "source": [
    "Next the Pandas `pd` library is used to read the Excel file and transform it into a DataFrame, and then assigns it into the `df` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GkrXLcCB8zux"
   },
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "input_file = r\"C:\\Users\\rjbru\\OneDrive\\Desktop\\2024_URA\\Understanding Animals\\Data Sets\\combined_csv_animal_flag_justanimals_location_flat (1).xlsx\"\n",
    "output_file = r\"C:\\Users\\rjbru\\OneDrive\\Desktop\\2024_URA\\Understanding Animals\\Data Sets\\sequenced_sightings_data.xlsx\"\n",
    "\n",
    "# Load the existing Excel file\n",
    "df = pd.read_excel(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Xdnu0HiLa_b"
   },
   "source": [
    "## Module: Manipulating the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EC23efAzQ9Sn"
   },
   "source": [
    "The `Date` and `Time` columns in the newly created DataFrame are combined into a single `datetime` column, which is required for the time analysis to be performed later in the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aq40gLSA80SL"
   },
   "outputs": [],
   "source": [
    "# Combine 'Date' and 'Time' into a single 'datetime' column\n",
    "df['datetime'] = pd.to_datetime(df['Date'].astype(str) + ' ' + df['Time'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DU48htO6RCZk"
   },
   "source": [
    "Next the DataFrame is organized by the `SpeciesList`, `locationID`, `cameraNum`, and `datetime` columns in the order specified. This will make further data analysis to determine close encounters more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LGIcphxD82FM"
   },
   "outputs": [],
   "source": [
    "# Sort data by SpeciesList, locationID, cameraNum, and datetime\n",
    "df.sort_values(by=['SpeciesList', 'locationID', 'cameraNum', 'datetime'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kiRCblYhLh9N"
   },
   "source": [
    "## Module: Grouping the Data into Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZSwxWtOPEk_"
   },
   "source": [
    "Next the `group_sequences()` function must be defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NUt_K5vPG30"
   },
   "source": [
    "It begins by initializing an empty `sequences` list to store the sequence data. Then `sequence_start_index` is implemented to keep track of the starting index of the current sequence, so that the number of images within a given sequence may be recorded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yv7TfQ_DPLo3"
   },
   "source": [
    "The function then iterates through rows within the DataFrame and compares each row to the previous row to check if the `SpeciesList`, `locationID`, and `cameraNum` values are the same and if the difference between the `datetime` fields is equal to or less than one minute. If any of the values are different or if the time difference is more than a minute it indicates the end of a sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7TKolelPT6z"
   },
   "source": [
    "\n",
    "After each sequence has been completed it is appended to the `sequences` list.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQSK9rrkPWOo"
   },
   "source": [
    "After the final sequence has been recorded, the script returns the completed list of sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "epN4USfz83yG"
   },
   "outputs": [],
   "source": [
    "def group_sequences(df):\n",
    "    sequences = []\n",
    "    sequence_start_index = 0\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        current_row = df.iloc[i]\n",
    "        previous_row = df.iloc[i - 1]\n",
    "\n",
    "        # Check if the current row is a continuation of the sequence\n",
    "        same_species = current_row['SpeciesList'] == previous_row['SpeciesList']\n",
    "        same_location = current_row['locationID'] == previous_row['locationID']\n",
    "        same_camera = current_row['cameraNum'] == previous_row['cameraNum']\n",
    "        within_one_minute = (current_row['datetime'] - previous_row['datetime']) <= timedelta(minutes=1)\n",
    "\n",
    "        if not (same_species and same_location and same_camera and within_one_minute):\n",
    "            # End the current sequence and start a new one\n",
    "            sequences.append(df.iloc[sequence_start_index:i].copy())\n",
    "            sequence_start_index = i\n",
    "\n",
    "    # Add the last sequence\n",
    "    sequences.append(df.iloc[sequence_start_index:].copy())\n",
    "\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kxa1r3uR1dM"
   },
   "source": [
    "The newly defined `group_sequences()` function is then used to sort the DataFrame and assign the modified DataFrame to the `sequences` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VbyEBHmr86KC"
   },
   "outputs": [],
   "source": [
    "# Group the data into sequences\n",
    "sequences = group_sequences(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCIs0OOWR1uG"
   },
   "source": [
    "An empty `grouped_data` list is then initialized to store the grouped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lwIsgx2R87zj"
   },
   "outputs": [],
   "source": [
    "# Create a new DataFrame to store the grouped data\n",
    "grouped_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwaXgYYKR17x"
   },
   "source": [
    "This ‘for’ block  iterates over each sequence and copies the first row while adding the `sequence_count` row to indicate the number of images within a sequence. This data is then appended to the `grouped_data` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NBLuDnDV8-B2"
   },
   "outputs": [],
   "source": [
    "for sequence in sequences:\n",
    "    first_entry = sequence.iloc[0].copy()  # Copy to avoid SettingWithCopyWarning\n",
    "    first_entry['sequence_count'] = len(sequence)  # The number of images in the sequence\n",
    "    grouped_data.append(first_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGMkz9AOR2ep"
   },
   "source": [
    "Next the data stored in the `grouped_data` is converted to a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ozYiewO8-o4"
   },
   "outputs": [],
   "source": [
    "grouped_df = pd.DataFrame(grouped_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjHfNW_mR2zU"
   },
   "source": [
    "The format of the `Date` column in the DataFrame is specified to be 'year-month-day’ to match the other data columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "scDPUCEV9BLk"
   },
   "outputs": [],
   "source": [
    "# Ensure the Date column is in \"Year-Month-Day\" format\n",
    "grouped_df['Date'] = pd.to_datetime(grouped_df['Date']).dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phjTWxNRLneV"
   },
   "source": [
    "## Module: Creating a New Excel File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUh7wvYUn-uC"
   },
   "source": [
    "The `grouped_df` is then saved to a new Excel file using the pandas `to_excel` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XiWuauho9C0Q"
   },
   "outputs": [],
   "source": [
    "# Save the grouped data to a new Excel file\n",
    "grouped_df.to_excel(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQSNYVRioBUQ"
   },
   "source": [
    "A print statement specifies the file path of the newly saved Excel file. This file will be used as the data file for the following scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j5hsZvTQ6Qrj"
   },
   "outputs": [],
   "source": [
    "print(f'Grouped data saved to {output_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffRPA0Q67hSp"
   },
   "source": [
    "# Documenting Interspecies and Intraspecies Close Encounters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lb6N8oVXoovN"
   },
   "source": [
    "The script outlined in this section analyzes the sequenced data and creates a new Excel file containing close encounters between animals of the same species, as well as animals from different species."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aokPlJ2MolKD"
   },
   "source": [
    "## Module: Importing the Necessary Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OiFPk0Rwpp9K"
   },
   "source": [
    "The script requires the `os`, `pandas`, and `datetime` modules as well as the `timedelta` class. These aid in navigating and creating file directories, data manipulation, and analyzing date and time information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K_BTGLl-oN5S"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_F3aA578p5d3"
   },
   "source": [
    "The source file path and output directory paths are assigned to the `file_path` and `output_dir` variables. `output_file_path` uses the `os.path.join()` function to append the desired file name to the end of the `output_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RzSSIXLVoPIb"
   },
   "outputs": [],
   "source": [
    "# File paths\n",
    "file_path = \"/content/drive/MyDrive/shared-data/Notebook datafiles/Close-encounters/sequenced_sightings_data.xlsx\"  # Change this to your file path\n",
    "output_dir = \"/content/drive/MyDrive/shared-data/Notebook datafiles/Close-encounters\"  # New directory path\n",
    "output_file_path = os.path.join(output_dir, 'combined_species_encounters.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G71hHDOUp5uc"
   },
   "source": [
    "This small ‘if’ block uses the `os` library to check if the output directory already exists, and creates one if it does not (along with any necessary parent directories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yQOdw7VwoPzB"
   },
   "outputs": [],
   "source": [
    "# Create the directory if it doesn’t exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OK42Hyzap591"
   },
   "source": [
    "The source data file is then read and assigned to the `df` variable using the pandas `pd.read_excel()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pVaDDQ5loROo"
   },
   "outputs": [],
   "source": [
    "# Load the Excel file\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I--RvJLpp1aT"
   },
   "source": [
    "## Module: Manipulating the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MVfQPJx9tu_C"
   },
   "source": [
    "The script then converts the `Date` and `Time` columns to the appropriate datetime data types for time data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SVjiOx_7oT90"
   },
   "outputs": [],
   "source": [
    "# Convert 'Time' column to datetime\n",
    "df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S').dt.time\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBTjcWHbtyXp"
   },
   "source": [
    "These columns are then combined into a single `DateTime` column for easier data analysis and manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tbwefiQqoVcD"
   },
   "outputs": [],
   "source": [
    "# Combine Date and Time back into a single datetime column for easier manipulation\n",
    "df['DateTime'] = pd.to_datetime(df['Date'].astype(str) + ' ' + df['Time'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkBhwIimt88R"
   },
   "source": [
    "Next the DataFrame is sorted by the `locationID` and `DateTime` columns in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gm8kwLiMoWEN"
   },
   "outputs": [],
   "source": [
    "# Sort the dataframe by locationID, DateTime\n",
    "df.sort_values(by=['locationID', 'DateTime'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bB7dDfaiusCI"
   },
   "source": [
    "An empty `results` list is initialized to store close encounter data as it is collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Yt3qq1CoXbt"
   },
   "outputs": [],
   "source": [
    "# Initialize list to store results\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcC51sdLvYyk"
   },
   "source": [
    "A unique counter is also initialized so that a unique encounter ID can be assigned to each close encounter that will be logged in the final Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AKQY_uTNoZDn"
   },
   "outputs": [],
   "source": [
    "# Initialize unique counter for UniqueEncounterID\n",
    "unique_counter = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbGFpACqvqab"
   },
   "source": [
    "## Module: Extracting Close Encounter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XSiqSxnwDSf"
   },
   "source": [
    "In this instance a close encounter is defined as animals being observed at the same location on the same day within ten minutes of each other (excluding instances that occur within a single sequence)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcBUoljtwD32"
   },
   "source": [
    "The script begins by grouping the DataFrame by the `locationID` value, creating a subset for each unique `locationID`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GK5SC-_FWfr2"
   },
   "source": [
    "The script then iterates over each subset and compares pairs of rows, determining the species and the time difference between sightings. This script records two types of encounters, encounters between the same species and encounters between different species. If a close encounter is discovered then its details are recorded along with a `unique_counter_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R0SgJv4EoapI"
   },
   "outputs": [],
   "source": [
    "# Process each locationID\n",
    "for location_id, group in df.groupby(['locationID']):\n",
    "    group = group.reset_index(drop=True)\n",
    "    for i in range(len(group) - 1):\n",
    "        species_i = group.loc[i, 'SpeciesList']\n",
    "        time_i = group.loc[i, 'DateTime']\n",
    "\n",
    "        for j in range(i + 1, len(group)):\n",
    "            species_j = group.loc[j, 'SpeciesList']\n",
    "            time_j = group.loc[j, 'DateTime']\n",
    "\n",
    "            # Calculate the time difference\n",
    "            time_diff = abs((time_j - time_i).total_seconds()) / 60  # in minutes\n",
    "\n",
    "            # Encounters: more than 2 to less than 10 minutes apart for same species and within 10 minutes for different species\n",
    "            if (2 < time_diff < 10 and species_i == species_j) or (time_diff <= 10 and species_i != species_j):\n",
    "                unique_encounter_id = f\"{location_id}_{time_i.strftime('%Y%m%d')}_{unique_counter}\"\n",
    "                unique_counter += 1\n",
    "                results.append({\n",
    "                    'LocationID': location_id,\n",
    "                    'Date': time_i.date(),\n",
    "                    'Species1': species_i,\n",
    "                    'Species2': species_j,\n",
    "                    'Time1': time_i.time(),\n",
    "                    'Time2': time_j.time(),\n",
    "                    'UniqueEncounterID': unique_encounter_id\n",
    "                })\n",
    "\n",
    "            # Efficiently terminate the loop for intraspecies if greater than 10 minutes\n",
    "            if time_diff > 10:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MWWI_gWDr9NI"
   },
   "source": [
    "## Module: Saving to a New Excel File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PW5sqDvWnX0"
   },
   "source": [
    "Here the `results` list containing the close encounters data is converted into a two-dimensional DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ra1WFeJsodBB"
   },
   "outputs": [],
   "source": [
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSL5srvIWnqZ"
   },
   "source": [
    "The DataFrame is then converted to an Excel file using the `to_excel()` function from the Pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L6WGvWRcoedp"
   },
   "outputs": [],
   "source": [
    "# Write the results to an Excel file\n",
    "results_df.to_excel(output_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BoeCHnKbWn6u"
   },
   "source": [
    "This print statement indicates the path to the newly saved Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cnFN_ye0ohbN"
   },
   "outputs": [],
   "source": [
    "print(f\"Results written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UONxyvkH7lZd"
   },
   "source": [
    "# Documenting Interspecies Close Encounters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "294gTzqmcZWo"
   },
   "source": [
    "The script outlined in this section analyzes the sequenced data and creates a new Excel file containing close encounters between animals from different species."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zh-8f7Y5dj9u"
   },
   "source": [
    "Since this script is performing relatively the same function as the previous close encounters script, the majority of the code will remain the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfaPTMK_dwwJ"
   },
   "source": [
    "The same libraries are downloaded and the information is converted to a DataFrame that is sorted by `locationID` and `DateTime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zZy-6jyHdP5X"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# File paths\n",
    "file_path = \"/content/drive/MyDrive/shared-data/Notebook datafiles/Close-encounters/sequenced_sightings_data.xlsx\"  # Change this to your file path\n",
    "output_dir = \"/content/drive/MyDrive/shared-data/Notebook datafiles/Close-encounters\"  # New directory path\n",
    "output_file_path = os.path.join(output_dir, 'combined_species_encounters.xlsx')\n",
    "\n",
    "# Create the directory if it doesn’t exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Convert 'Time' column to datetime\n",
    "df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S').dt.time\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
    "\n",
    "# Combine Date and Time back into a single datetime column for easier manipulation\n",
    "df['DateTime'] = pd.to_datetime(df['Date'].astype(str) + ' ' + df['Time'].astype(str))\n",
    "\n",
    "# Sort the dataframe by locationID, DateTime\n",
    "df.sort_values(by=['locationID', 'DateTime'], inplace=True)\n",
    "\n",
    "# Initialize list to store results\n",
    "results = []\n",
    "\n",
    "# Initialize unique counter for UniqueEncounterID\n",
    "unique_counter = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hK2iNVcqcI7a"
   },
   "source": [
    "This script, however, only records close encounters between animals of different species. In this instance a close encounter is defined as animals of different species being observed at the same location on the same day within ten minutes of each other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hqs3Rh1fpE9"
   },
   "source": [
    "This code block operates very similarly to the one in the previous script, grouping the DataFrame by `locationID` and iterating over each subset and appending close encounters to the `results` list when found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-9SxpsgVdQsb"
   },
   "outputs": [],
   "source": [
    "# Process each locationID\n",
    "for location_id, group in df.groupby(['locationID']):\n",
    "    group = group.reset_index(drop=True)\n",
    "    for i in range(len(group) - 1):\n",
    "        species_i = group.loc[i, 'SpeciesList']\n",
    "        time_i = group.loc[i, 'DateTime']\n",
    "\n",
    "        for j in range(i + 1, len(group)):\n",
    "            species_j = group.loc[j, 'SpeciesList']\n",
    "            time_j = group.loc[j, 'DateTime']\n",
    "\n",
    "            # Calculate the time difference\n",
    "            time_diff = abs((time_j - time_i).total_seconds()) / 60  # in minutes\n",
    "\n",
    "            # Record encounters of different species within 10 minutes apart\n",
    "            if time_diff <= 10 and species_i != species_j:\n",
    "                unique_encounter_id = f\"{location_id}_{time_i.strftime('%Y%m%d')}_{unique_counter}\"\n",
    "                unique_counter += 1\n",
    "                results.append({\n",
    "                    'LocationID': location_id,\n",
    "                    'Date': time_i.date(),\n",
    "                    'Species1': species_i,\n",
    "                    'Species2': species_j,\n",
    "                    'Time1': time_i.time(),\n",
    "                    'Time2': time_j.time(),\n",
    "                    'UniqueEncounterID': unique_encounter_id\n",
    "                })\n",
    "\n",
    "            # Efficiently terminate the loop if time difference is greater than 10 minutes\n",
    "            if time_diff > 10:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FkT2NJ6FfyFE"
   },
   "source": [
    "The `results` list is then converted to a DataFrame and saved as an Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zhcvMDrU55Uk"
   },
   "outputs": [],
   "source": [
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Write the results to an Excel file\n",
    "results_df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Results written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1e89dTd_8SGt"
   },
   "source": [
    "# Plotting Close Encounters Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVv1nQtLp0XH"
   },
   "source": [
    "This script extracts data from the newly generated Excel file and visualizes it in the form of a network graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqmjIiOfo1gY"
   },
   "source": [
    "## Module: Importing the Necessary Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SnfcGRgGrJfE"
   },
   "source": [
    "Importing the following libraries will enable the script to read and write files, create and manipulate network graphs, generate plots and customizable visual elements, manipulate image data, and handle array data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXAssB3an8vD"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import PathPatch, FancyBboxPatch, BoxStyle\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIUR9OJurKBe"
   },
   "source": [
    "Here the paths to the previously generated close encounters Excel file and the directory containing silhouette image files (if applicable) are defined. The data in the Excel file is loaded into a DataFrame for easier analysis and manipulation later in the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3qmjagOJn-2m"
   },
   "outputs": [],
   "source": [
    "# File paths\n",
    "results_file_path = \"/content/drive/MyDrive/shared-data/Notebook datafiles/Close-encounters/combined_species_encounters.xlsx\"\n",
    "silhouettes_dir = \"/content/drive/MyDrive/shared-data/Notebook datafiles/Close-encounters/silhouettes\"  # Directory containing species silhouette images\n",
    "\n",
    "# Load the results from the previous Excel file\n",
    "df = pd.read_excel(results_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vcWK4jperKU4"
   },
   "source": [
    "These print statements print the first five rows of the DataFrame to ensure it has been loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6dF3J2PjoAqq"
   },
   "outputs": [],
   "source": [
    "# Verify the data loaded correctly\n",
    "print(\"Data preview:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krgBZM3No3b0"
   },
   "source": [
    "## Module: Preparing the Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U033b5vDzoTx"
   },
   "source": [
    "Here an empty graph is initialized and assigned to the variable `G`. Within this graph object the network graph will be constructed by adding nodes (species) and edges (encounters between species)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7oVwr7cKoGVQ"
   },
   "outputs": [],
   "source": [
    "# Create the network graph\n",
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtK5DdcgzqXQ"
   },
   "source": [
    "This code block establishes unique colors to represent each locationID within the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3bwjINOn1NIY"
   },
   "source": [
    "The function `df[‘LocationID’].unique()` extracts an array of unique values from the `locationID` column and assigns those values to the `unique_location_ids` variable. The `get_cmap` function is then used to retrieve the `tab20c` color map. `len(unique_location_ids)` specifies the number of colors required for the graph. The color map is then assigned to the `colors` variable, which is now a color map object that can be used to get a unique color for each `locationID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w1GFA9_KoHrq"
   },
   "outputs": [],
   "source": [
    "# Define a list of colors for different LocationIDs\n",
    "unique_location_ids = df['LocationID'].unique()\n",
    "colors = plt.get_cmap('tab20c', len(unique_location_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zkN179R3agq"
   },
   "source": [
    "This line of code creates the `dictionary location_color_map` where the keys are locationIDs and the values are colors, allowing each unique location to be visually differentiated in the network graph. These locationID color pairs are created using a dictionary comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0hUQVqGRoIMA"
   },
   "outputs": [],
   "source": [
    "# Prepare color mapping for each unique LocationID\n",
    "location_color_map = {loc_id: colors(i) for i, loc_id in enumerate(unique_location_ids)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fv2XSiHC3ful"
   },
   "source": [
    "Here an empty `edge_counters` dictionary is initialized to track how many times each edge (close encounter) is added to the graph. This ensures that each line is manipulated to have unique curvature and prevent potential obstruction of edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d0LbOS8ioKSc"
   },
   "outputs": [],
   "source": [
    "# Track how many times each edge is added to ensure unique curvature and volume depiction for each encounter\n",
    "edge_counters = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOTLOvS84R21"
   },
   "source": [
    "This code block iterates over each row of the DataFrame and extracts the species, locationID, and associated location color. `edge = tuple(sorted((species1, species2)))` creates an edge between each species involved in the close encounter. `G.add_edge()` adds an edge between species and species2 to the graph object G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WRyC16hRoLpi"
   },
   "outputs": [],
   "source": [
    "# Build the graph and assign colors\n",
    "for index, row in df.iterrows():\n",
    "    species1, species2 = row['Species1'], row['Species2']\n",
    "    location_id = row['LocationID']\n",
    "    color = location_color_map[location_id]\n",
    "\n",
    "    edge = tuple(sorted((species1, species2)))  # Ensure consistent edge representation\n",
    "    if edge not in edge_counters:\n",
    "        edge_counters[edge] = 0\n",
    "\n",
    "    edge_counters[edge] += 1\n",
    "    G.add_edge(species1, species2, color=color, weight=edge_counters[edge])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYBxPXHw6CYR"
   },
   "source": [
    "Here the `networkx` library is used to arrange the nodes within graph `G` in a circular format with a radius of `2` units. This helps create a clear network graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JB3CGJxhoNXF"
   },
   "outputs": [],
   "source": [
    "# Node positions in a circular layout with increased radius\n",
    "pos = nx.circular_layout(G, scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kvSFD46-bgO"
   },
   "source": [
    "Here a 20x20” plotting space is created using the `matplotlib` library. This ensures that there is sufficient space for the detailed network graph to be plotted in a legible manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JnJZPtRYoOo0"
   },
   "outputs": [],
   "source": [
    "# Draw the network graph\n",
    "fig, ax = plt.subplots(figsize=(20, 20))  # Increased figure size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAT7dCgZpDEN"
   },
   "source": [
    "## Module: Loading Silhouette Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WflzMdgoAWW2"
   },
   "source": [
    "In order to represent the species nodes with silhouettes, the silhouette image files must be obtained from the specified directory and normalized so that they are relatively consistent across nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6Stox8ZAXVa"
   },
   "source": [
    "The `get_image()` function is defined to load an image from the directory and then convert it to `RBGA` mode. This allows the script to process the image so that all white pixels are fully transparent, if not already. The image is then resized to the desired height while maintaining the same aspect ratio to minimize distortion, and the function then returns an `OffsetImage` object to be used in plotting the network graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iK5QIXd-oQJV"
   },
   "outputs": [],
   "source": [
    "# Helper function to import and convert images\n",
    "def get_image(path, target_height):\n",
    "    try:\n",
    "        img = Image.open(path)\n",
    "        img = img.convert(\"RGBA\")\n",
    "\n",
    "        datas = img.getdata()\n",
    "        new_data = []\n",
    "        for item in datas:\n",
    "            if item[0] > 200 and item[1] > 200 and item[2] > 200:\n",
    "                new_data.append((255, 255, 255, 0))\n",
    "            else:\n",
    "                new_data.append(item)\n",
    "        img.putdata(new_data)\n",
    "\n",
    "        width, height = img.size\n",
    "        new_width = int((target_height / height) * width)\n",
    "        img = img.resize((new_width, target_height), Image.LANCZOS)\n",
    "\n",
    "        return OffsetImage(img)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgvF9hr3AgHn"
   },
   "source": [
    "This ‘for’ block iterates over each node in the network graph and adds the species silhouette, or displays the species name. `for node, (x, y) in pos.items():` starts the loop that iterates over each node in the `pos` dictionary, returning pairs of `(node, (x, y))` where `node` is the species name and `(x, y)` are its coordinates in the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TuHcFRbjCw-8"
   },
   "source": [
    "`os.path.join(silhouettes_dir, f”{node}.jpg”)` creates a path to the silhouette image file. The script assumes that the silhouette image files are named according to their species, such as ‘fox.jpg’. The image extension `.jpg` can be altered according to the desired file type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nf8fn4_6C2er"
   },
   "source": [
    "The `get_image()` function is then used to load and process the image and ensures that all images have the same height (in this instance the `target_height` parameter has been set to `120`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irJ9PoRTC9FV"
   },
   "source": [
    "The embedded ‘if’ block checks if the `get_image()` function has successfully loaded and preprocessed the image, and then places the `OffsetImage` at the `(x, y)` coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mOYURtVmDC3T"
   },
   "source": [
    "The ‘else’ block ensures that if a silhouette image was not successfully loaded a box containing the species name is placed at the `(x, y)` coordinates instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oj0aOjcPoSEy"
   },
   "outputs": [],
   "source": [
    "# Add silhouette images as nodes, or species name if silhouettes are not available\n",
    "for node, (x, y) in pos.items():\n",
    "    img_path = os.path.join(silhouettes_dir, f\"{node}.jpg\")  # Adjust extension as needed (.png, .jpeg)\n",
    "    image = get_image(img_path, target_height=120)\n",
    "    if image:\n",
    "        ab = AnnotationBbox(image, (x, y), frameon=False)\n",
    "        ax.add_artist(ab)\n",
    "    else:\n",
    "        # If no silhouette found, draw the species name with an oval, white background\n",
    "        bbox_props = dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"black\", lw=2)\n",
    "        ax.text(x, y, node, ha=\"center\", va=\"center\", rotation=0, size=12, bbox=bbox_props)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nP2Ihb6HpRoT"
   },
   "source": [
    "## Module: Determining Line Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKn8oMc6EImE"
   },
   "source": [
    "The `get_line_style()` function determines the line styles that will be used to represent the volume of close encounters between each species at each location. The edges will be solid for more than ten close encounters, dashed for 5-10 close encounters, and dotted for 1-4 close encounters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dvtE9Zm9oUCu"
   },
   "outputs": [],
   "source": [
    "# Function to determine line style based on the number of encounters\n",
    "def get_line_style(num_encounters):\n",
    "    if (num_encounters > 10):  # Define thresholds as per your dataset\n",
    "        return 'solid'\n",
    "    elif (5 <= num_encounters <= 10):\n",
    "        return (0, (5, 5))  # dashed\n",
    "    else:\n",
    "        return (0, (1, 3))  # dotted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8IKu3R5OEL3d"
   },
   "source": [
    "This code block defines the `draw_curved_edges()` function which takes on the following inputs: `G` (the graph object containing the nodes and edges), `pos` (the dictionary containing node coordinates), `ax` (the matplotlib axis object indicating where the graph will be drawn), and `edge_counters` (a dictionary to keep track of the number of edges between each pair of nodes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LXOsGixon1tb"
   },
   "source": [
    "A base curvature radius is set to `0.01` (the lower the value, the less severe the curve of the edges). This value is then manipulated based on the number of edges between each pair of nodes, ensuring that no edge is obscured from view. `line_style = get_line_style(num_encounters)` determines the line type to be used for the edge based on the volume of close encounters between the species pair at the given location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GFLwF9gsoV7Q"
   },
   "outputs": [],
   "source": [
    "# Function to draw curved edges towards the center of the circle with reduced curvature\n",
    "def draw_curved_edges(G, pos, ax, edge_counters):\n",
    "    base_rad = 0.01  # Further reduce curvature radius for more subtle curves\n",
    "\n",
    "    for (u, v, d) in G.edges(data=True):\n",
    "        color = G[u][v]['color']\n",
    "        num_encounters = d['weight']\n",
    "\n",
    "        edge = tuple(sorted((u, v)))  # Ensure consistent edge representation for edge_counters lookup\n",
    "        rad = min(0.1, base_rad * edge_counters[edge])  # Use edge_counters for slight variation in curvature, capped at 0.1\n",
    "\n",
    "        line_style = get_line_style(num_encounters)  # Determine line style based on encounter volume\n",
    "\n",
    "        # Compute the control points\n",
    "        ctrl_x, ctrl_y = (pos[u][0] + pos[v][0]) / 2, (pos[u][1] + pos[v][1]) / 2\n",
    "        dx, dy = pos[v][0] - pos[u][0], pos[v][1] - pos[u][1]\n",
    "\n",
    "        # Adjust control points towards the center even less aggressively\n",
    "        ctrl_x -= rad * dy\n",
    "        ctrl_y += rad * dx\n",
    "\n",
    "        verts = [(pos[u][0], pos[u][1]), (ctrl_x, ctrl_y), (pos[v][0], pos[v][1])]\n",
    "        codes = [Path.MOVETO, Path.CURVE3, Path.CURVE3]\n",
    "\n",
    "        path = Path(verts, codes)\n",
    "        patch = PathPatch(path, facecolor='none', edgecolor=color, lw=1, linestyle=line_style)\n",
    "        ax.add_patch(patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEBujPrlp-Sd"
   },
   "source": [
    "This line calls the previously defined `draw_curved_edges(G, pos, ax, edge_counters)` function. The function iterates through each edge in graph `G` and determines the curvature of each edge based on the `edge_counters` value. It then draws the edges using `matplotlib` and applies the required color and linetype to represent locationID and the volume of close encounters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xoZEzbjioXws"
   },
   "outputs": [],
   "source": [
    "# Draw edges\n",
    "draw_curved_edges(G, pos, ax, edge_counters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7M05LFPqJcA"
   },
   "source": [
    "Here the plot limit for the graph is defined using the `plt.xlim()` and `plt.ylim()` functions. `plt.axis(‘off’)` ensures that axis lines, ticks, and labels will not be displayed in the final graph. This will provide a more legible and visually appealing network graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HQxpVj6toZhr"
   },
   "outputs": [],
   "source": [
    "# Set plot limits\n",
    "plt.xlim(-2.5, 2.5)  # Adjust based on the graph size\n",
    "plt.ylim(-2.5, 2.5)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBHFABpXpauA"
   },
   "source": [
    "## Module: Creating the Legends and Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_QX5TL3ttRb"
   },
   "source": [
    "This snippet uses a list comprehension to create a list of legend entries, with each entry associating a unique color with a locationID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KWNWmDD_obDA"
   },
   "outputs": [],
   "source": [
    "# Create the legend mapping colors to LocationIDs\n",
    "# Legend elements for colors\n",
    "legend_elements_colors = [Line2D([0], [0], color=color, lw=4, label=f'Location ID {loc_id}')\n",
    "                          for loc_id, color in location_color_map.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqODEn_ztzaq"
   },
   "source": [
    "This creates an additional legend displaying the line types and associated values regarding the volume of close encounters between a species pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3OdUyWbkocnh"
   },
   "outputs": [],
   "source": [
    "# Legend elements for line types\n",
    "legend_elements_lines = [Line2D([0], [0], color='black', lw=2, linestyle='solid', label='> 10 encounters'),\n",
    "                         Line2D([0], [0], color='black', lw=2, linestyle=(0, (5, 5)), label='5-10 encounters'),\n",
    "                         Line2D([0], [0], color='black', lw=2, linestyle=(0, (1, 3)), label='< 5 encounters')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2jFdVFMu7ZL"
   },
   "source": [
    "Next the script creates a combined legend to display the color associated with each locationID, and the linetype associate for each category of volume of close encounters. Here the specific characteristics of the first legend displaying color and locationID is specified, such as title and font size. The `ax.add_artist()` function creates the legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5inXpfwoeOj"
   },
   "outputs": [],
   "source": [
    "# Create the combined legend and ensure both legends are displayed\n",
    "first_legend = ax.legend(handles=legend_elements_colors, title=\"Location ID\", title_fontsize='13', fontsize='12', loc='upper left', bbox_to_anchor=(1.05, 1), borderaxespad=0.5)\n",
    "ax.add_artist(first_legend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8TFPYB7ySDN"
   },
   "source": [
    "Here the characteristics of the second legend is specified and the `ax.add_artist()` function creates the legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IR7GWhLZogc7"
   },
   "outputs": [],
   "source": [
    "# Add a second legend for the line types\n",
    "second_legend = ax.legend(handles=legend_elements_lines, title=\"Encounters\", title_fontsize='13', fontsize='12', loc='upper left', bbox_to_anchor=(1.05, 0.8), borderaxespad=0.5)\n",
    "ax.add_artist(second_legend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHWXArC00zL5"
   },
   "source": [
    "The `plt.suptitle()` function is used to create a centered title for the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6XsZFQ81oiCZ"
   },
   "outputs": [],
   "source": [
    "# Title, centered above the graph\n",
    "plt.suptitle(\"Close Encounters Across Species and Sites\", fontsize=20, y=0.92)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7iZvnBBzpge0"
   },
   "source": [
    "## Module: Saving the Close Encounters Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6T-Al8E1oaS"
   },
   "source": [
    "The plot is saved to a file path constructed using the `os.path.join()` and `os.path.dirname()` functions. The arguments within the `plt.savefig()` function ensure that the plot is saved as a pdf file with some padding, and the final line within the code snippet ensures that there are no overlapping elements within the graph and all of the elements are neatly aligned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F-Txf3l-ojpF"
   },
   "outputs": [],
   "source": [
    "# Save the plot as a .pdf file\n",
    "output_path_pdf = os.path.join(os.path.dirname(results_file_path), \"network_graph.pdf\")\n",
    "plt.savefig(output_path_pdf, format='pdf', bbox_inches='tight', pad_inches=0.5)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71456ppL115x"
   },
   "source": [
    "This print statement informs the user that the plot has been successfully generated and saved to the output file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RT_mG8foolaW"
   },
   "outputs": [],
   "source": [
    "# Print the location where the PDF file was saved\n",
    "print(f\"The PDF file was saved at: {output_path_pdf}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOiPfE6+PdPxNb8WsV/leRX",
   "collapsed_sections": [
    "b8ddXiaw7Ihy",
    "GLUYt1kFIfjI",
    "2n1NVqn3KtJK",
    "1Xdnu0HiLa_b",
    "kiRCblYhLh9N",
    "phjTWxNRLneV",
    "aokPlJ2MolKD",
    "I--RvJLpp1aT",
    "wqmjIiOfo1gY",
    "krgBZM3No3b0",
    "nAT7dCgZpDEN",
    "nP2Ihb6HpRoT",
    "XBHFABpXpauA"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
