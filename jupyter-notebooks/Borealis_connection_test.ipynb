{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<a target=\"_blank\" href=\"https://colab.research.google.com/github/umanitoba-meagher-projects/public-experiments/blob/main/jupyter-notebooks/Borealis_connection_test.ipynb\">\n  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n</a>"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KperHPV0zmyA"
   },
   "source": [
    "## Borealis connection test\n",
    "\n",
    "- This is a test for downloading public content hosted on Borealis using python.\n",
    "- The first step is to print out a list of files in the dataset - this provides the file id that is needed to download a given file from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BYDfYcy_7QMh"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# No API token needed for public datasets!\n",
    "BOREALIS_SERVER = \"https://borealisdata.ca\"\n",
    "\n",
    "def get_public_dataset_info(persistent_id):\n",
    "    \"\"\"\n",
    "    Get information about a public dataset\n",
    "    \"\"\"\n",
    "    url = f\"{BOREALIS_SERVER}/api/datasets/:persistentId/\"\n",
    "    params = {\"persistentId\": persistent_id}\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        dataset_info = response.json()\n",
    "    else:\n",
    "        print(f\"Cannot access dataset: {response.status_code}\")\n",
    "        return None\n",
    "    \"\"\"\n",
    "    Get a list of files in a public dataset\n",
    "    \"\"\"\n",
    "    # Access the list of files from the dataset_info dictionary\n",
    "    files_list = dataset_info['data']['latestVersion']['files']\n",
    "\n",
    "    # Create an empty list to store file information\n",
    "    file_info_list = []\n",
    "\n",
    "    # Iterate through the files list and append file ID and filename to the list\n",
    "    for file_info in files_list:\n",
    "        file_id = file_info['dataFile']['id']\n",
    "        filename = file_info['dataFile']['filename']\n",
    "        file_info_list.append({\"file_id\": file_id, \"filename\": filename})\n",
    "\n",
    "    return file_info_list\n",
    "\n",
    "\n",
    "# Example usage\n",
    "public_doi = \"doi:10.5683/SP3/H3HGWF\" # doi for 'Understanding Animals jupyter notebook data'\n",
    "dataset_info = get_public_dataset_info(public_doi)\n",
    "print(dataset_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-g7De-Ht8_Wq"
   },
   "source": [
    "## download a file\n",
    "\n",
    "- The next step is to download a selected file from the dataset, using the file id acquired in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9U1zSmVzziAs"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def download_public_file(file_id, save_path=\"./\"):\n",
    "    \"\"\"\n",
    "    Download a specific public file from a dataset by its file ID\n",
    "    No authentication required\n",
    "    \"\"\"\n",
    "    url = f\"{BOREALIS_SERVER}/api/access/datafile/{file_id}\"\n",
    "\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Determine filename from headers or URL\n",
    "        filename = None\n",
    "        if \"Content-Disposition\" in response.headers:\n",
    "            cd = response.headers[\"Content-Disposition\"]\n",
    "            # Try to extract filename from content disposition\n",
    "            if \"filename=\" in cd:\n",
    "                filename = cd.split(\"filename=\")[1].strip('\"')\n",
    "\n",
    "        # Fallback to extracting from URL if header not available or malformed\n",
    "        if not filename:\n",
    "             filename = url.split(\"/\")[-1]\n",
    "\n",
    "\n",
    "        file_path = f\"{save_path}/{filename}\"\n",
    "\n",
    "        with open(file_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "\n",
    "        print(f\"✅ File downloaded to {file_path}\")\n",
    "        return file_path\n",
    "    else:\n",
    "        print(f\"❌ Error {response.status_code}: File may be restricted or not found\")\n",
    "        return None\n",
    "\n",
    "# Download the selected file from the Borealis dataset\n",
    "file_id = 965302 # file id for deer-100.zip\n",
    "download_public_file(file_id, \"./\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zevnsktw04wd"
   },
   "source": [
    "## download the data\n",
    "\n",
    "The next step is to download the files that you need, and unzip the files if they've been zipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6d3a29d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "def is_zip_file(filepath):\n",
    "    \"\"\"\n",
    "    Checks if a file is a valid zip file.\n",
    "    \"\"\"\n",
    "    return zipfile.is_zipfile(filepath)\n",
    "\n",
    "def unzip_file(filepath, extract_path=\"./\"):\n",
    "    \"\"\"\n",
    "    Unzips a zip file to a specified path and returns the name of the top-level extracted folder.\n",
    "    Returns None if not a zip file or extraction fails.\n",
    "    \"\"\"\n",
    "    if is_zip_file(filepath):\n",
    "        try:\n",
    "            with zipfile.ZipFile(filepath, 'r') as zip_ref:\n",
    "                # Get the name of the top-level directory within the zip\n",
    "                # Assumes there is a single top-level directory\n",
    "                top_level_folder = None\n",
    "                for file_info in zip_ref.infolist():\n",
    "                    parts = file_info.filename.split('/')\n",
    "                    if parts[0] and len(parts) > 1:\n",
    "                        top_level_folder = parts[0]\n",
    "                        break # Assuming the first entry gives the top-level folder\n",
    "\n",
    "\n",
    "                zip_ref.extractall(extract_path)\n",
    "                print(f\"✅ Successfully unzipped {filepath} to {extract_path}\")\n",
    "                return top_level_folder\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error unzipping {filepath}: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"ℹ️ {filepath} is not a valid zip file.\")\n",
    "        return None\n",
    "\n",
    "# identify the file to be unzipped\n",
    "downloaded_file_path = \"./\" + str(file_id)\n",
    "\n",
    "if is_zip_file(downloaded_file_path):\n",
    "    extracted_folder_name = unzip_file(downloaded_file_path, \"./\") # Extract to the current directory\n",
    "    if extracted_folder_name:\n",
    "        print(f\"Extracted folder name: {extracted_folder_name}\")\n",
    "else:\n",
    "    print(f\"The file {downloaded_file_path} is not a zip file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jeqoqaueCj7h"
   },
   "source": [
    "## review zip file contents\n",
    "\n",
    "- optionally review the contents of the zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cd3c057d",
    "outputId": "1b1d8e09-5aba-4564-9f44-c46e30c7d48f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of the unzipped directory (recursive listing):\n",
      "deer_100/\n",
      "    deer_100/\n",
      "        deer_139.jpg\n",
      "        deer_287.jpg\n",
      "        deer_030.jpg\n",
      "        deer_051.jpg\n",
      "        deer_036.jpg\n",
      "        deer_169.jpg\n",
      "        deer_033.jpg\n",
      "        deer_194.jpg\n",
      "        deer_170.jpg\n",
      "        deer_339.jpg\n",
      "        deer_185.jpg\n",
      "        deer_035.jpg\n",
      "        deer_342.jpg\n",
      "        deer_198.jpg\n",
      "        deer_072.jpg\n",
      "        deer_065.jpg\n",
      "        deer_462.jpg\n",
      "        deer_012.jpg\n",
      "        deer_283.jpg\n",
      "        deer_187.jpg\n",
      "        deer_471.jpg\n",
      "        deer_207.jpg\n",
      "        deer_324.jpg\n",
      "        deer_093.jpg\n",
      "        deer_270.jpg\n",
      "        deer_048.jpg\n",
      "        deer_372.jpg\n",
      "        deer_498.jpg\n",
      "        deer_055.jpg\n",
      "        deer_162.jpg\n",
      "        deer_205.jpg\n",
      "        deer_239.jpg\n",
      "        deer_257.jpg\n",
      "        deer_264.jpg\n",
      "        deer_016.jpg\n",
      "        deer_217.jpg\n",
      "        deer_047.jpg\n",
      "        deer_496.jpg\n",
      "        deer_241.jpg\n",
      "        deer_238.jpg\n",
      "        deer_289.jpg\n",
      "        deer_204.jpg\n",
      "        deer_301.jpg\n",
      "        deer_223.jpg\n",
      "        deer_355.jpg\n",
      "        deer_421.jpg\n",
      "        deer_008.jpg\n",
      "        deer_133.jpg\n",
      "        deer_298.jpg\n",
      "        deer_463.jpg\n",
      "        deer_448.jpg\n",
      "        deer_013.jpg\n",
      "        deer_489.jpg\n",
      "        deer_091.jpg\n",
      "        deer_441.jpg\n",
      "        deer_414.jpg\n",
      "        deer_002.jpg\n",
      "        deer_199.jpg\n",
      "        deer_288.jpg\n",
      "        deer_435.jpg\n",
      "        deer_280.jpg\n",
      "        deer_070.jpg\n",
      "        deer_254.jpg\n",
      "        deer_353.jpg\n",
      "        deer_341.jpg\n",
      "        deer_250.jpg\n",
      "        deer_123.jpg\n",
      "        deer_112.jpg\n",
      "        deer_032.jpg\n",
      "        deer_040.jpg\n",
      "        deer_433.jpg\n",
      "        deer_106.jpg\n",
      "        deer_231.jpg\n",
      "        deer_333.jpg\n",
      "        deer_303.jpg\n",
      "        deer_403.jpg\n",
      "        deer_424.jpg\n",
      "        deer_228.jpg\n",
      "        deer_348.jpg\n",
      "        deer_181.jpg\n",
      "        deer_404.jpg\n",
      "        deer_469.jpg\n",
      "        deer_395.jpg\n",
      "        deer_260.jpg\n",
      "        deer_046.jpg\n",
      "        deer_014.jpg\n",
      "        deer_321.jpg\n",
      "        deer_285.jpg\n",
      "        deer_331.jpg\n",
      "        deer_153.jpg\n",
      "        deer_426.jpg\n",
      "        deer_102.jpg\n",
      "        deer_107.jpg\n",
      "        deer_390.jpg\n",
      "        deer_197.jpg\n",
      "        deer_140.jpg\n",
      "        deer_444.jpg\n",
      "        deer_020.jpg\n",
      "        deer_356.jpg\n",
      "        deer_011.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Contents of the unzipped directory (recursive listing):\")\n",
    "\n",
    "if os.path.exists(extracted_folder_name):\n",
    "    for root, dirs, files in os.walk(extracted_folder_name):\n",
    "        level = root.replace(extracted_folder_name, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print(f'{indent}{os.path.basename(root)}/')\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for f in files:\n",
    "            print(f'{subindent}{f}')\n",
    "else:\n",
    "    print(f\"The directory {extracted_folder_name} does not exist.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}