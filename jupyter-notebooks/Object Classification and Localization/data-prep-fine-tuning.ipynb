{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/mmeagher/experiments/blob/main/jupyter-notebooks/Object%20Classification%20and%20Localization/data-prep-fine-tuning.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PIOfm1Vf0jRQ"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Ryleigh J. Bruce\n",
    "Date: June 17, 2024\n",
    "\n",
    "Purpose: Preparing a dataset for fine tuning a YOLO model.\n",
    "\n",
    "\n",
    "Note: The author generated this text in part with GPT-4,\n",
    "OpenAI’s large-scale language-generation model. Upon generating\n",
    "draft code, the authors reviewed, edited, and revised the code\n",
    "to their own liking and takes ultimate responsibility for\n",
    "the content of this code.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook walks through the process of preparing datasets for training YOLO object detection models. It shows how to download datasets like COCO (Common Objects in Context), convert them to the right format, and split them into training and validation sets. The guide is designed to make dataset preparation easier and more automated for computer vision projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critical Uses & Adaptability\n",
    "\n",
    "### What the Notebook Can Be Used For:\n",
    "**Dataset Exploration:** This notebook facilitates the exploration and preparation of datasets for object detection.\n",
    "\n",
    "**Educational Purposes & Demonstrations:** The notebook is a guide for use of Python scripts and machine learning libraries to process image datasets.\n",
    "\n",
    "### How the Notebook Can Be Adapted:\n",
    "\n",
    "**Integration with Spatial Design:** This notebook can be applied to site analysis by preparing datasets specific to design projects. The code blocks for dataset preparation and export are particularly relevant.\n",
    "\n",
    "**Variables & Customization:** Users can modify variables such as dataset paths, split percentages, and export directories to suit their needs. The code block for loading datasets using `fiftyone.zoo.load_zoo_dataset` demonstrates how to swap datasets effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNDYJwYIKmw-"
   },
   "source": [
    "### Mount the Notebook to Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6GgQGxBWvFP"
   },
   "source": [
    "Here we import the drive module that allows us to link the Colab environment with our google drive, where the desired data set is stored. This allows us to access any files located within Google Drive and interact with them directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28999,
     "status": "ok",
     "timestamp": 1718336592344,
     "user": {
      "displayName": "Ryleigh Bruce",
      "userId": "04866625339349492872"
     },
     "user_tz": 300
    },
    "id": "rMnCIhfoNmo8",
    "outputId": "43dd3f7a-29a9-4dc2-b0b8-7b9d6ea44179"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CO8v6QZr5hW1"
   },
   "source": [
    "### Download a Dataset from FiftyOne Data Zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQ4r4C6U8D6S"
   },
   "source": [
    "The FiftyOne Data Zoo is an open-source tool for building and downloading high quality datasets for training machine learning models. Datasets are often preprocessed, minimizing the amount of labor required for preparing the dataset for training. More information about FiftyOne Data Zoo can be found at the following link: https://docs.voxel51.com/user_guide/dataset_zoo/index.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Y5nb3B3DcPT"
   },
   "source": [
    "### Install the Necessary Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkPFTzy38Etn"
   },
   "source": [
    "First the FiftyOne library must be installed in the colab environment. This is done using the `!pip install` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 68194,
     "status": "ok",
     "timestamp": 1718645258000,
     "user": {
      "displayName": "Ryleigh Bruce",
      "userId": "04866625339349492872"
     },
     "user_tz": 300
    },
    "id": "a0rYckXuPGC5",
    "outputId": "961ea3ec-62b8-4910-f5bb-b4e09c8f3511"
   },
   "outputs": [],
   "source": [
    "!pip install fiftyone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zx3nUekJ8FCI"
   },
   "source": [
    "Both the `fiftyone` and `fiftyone.zoo` modules must be imported in order to interact with the collection of datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJSDdaxU7948"
   },
   "outputs": [],
   "source": [
    "import fiftyone\n",
    "import fiftyone.zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJijH1Uv8FQP"
   },
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCslgtCVDvji"
   },
   "source": [
    "Within the ‘try’ block, the `fiftyone.zoo.load_zoo_dataset()` function is used to load a specified dataset into the `dataset` variable. In this example the script is attempting to download a portion of the COCO dataset. The `split` variable indicates whether the training or validation portion of the dataset should be loaded, and `label_types` defines what types of labels need to be loaded with the dataset. `classes` specifies a subset of classes to be downloaded from the dataset, rather than the entire COCO dataset. This drastically reduces the amount of time required to download the images. `max_samples` allows the user to specify the maximum number of images to be downloaded from the subset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXLRWRudFAfd"
   },
   "source": [
    "The ‘except’ block ensures that any errors that occur are caught and a corresponding error message is printed along with the exception details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HJ1AYydL5mWM"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    dataset = fiftyone.zoo.load_zoo_dataset(\n",
    "      \"coco-2017\", #adjuat this string according to the desired dataset\n",
    "      split=\"train\", #optional\n",
    "      label_types=[\"detections\", \"segmentations\"],\n",
    "      classes=['bird', 'cat', 'dog', 'bear'], #optional\n",
    "      max_samples=3000,\n",
    "    )\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cj7ALFQA8FgB"
   },
   "source": [
    "### Export the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCHDtO3cFPrt"
   },
   "source": [
    "The `export_dir` variable specifies the path for the dataset to be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y4JxE4lC8AIV"
   },
   "outputs": [],
   "source": [
    "export_dir = \"/content/drive/MyDrive/shared-data/Notebook datafiles/Finetuning-YOLOv5-animals/coco\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_Le7XKX8F61"
   },
   "source": [
    "The export directory path, export format, label field, and split are defined within the ‘try’ block. It is critical to ensure that `dataset_type` is `fiftyone.types.YOLOv5Dataset`, or else the dataset will be unusable for fine tuning the YOLO model. A print statement alerts the user when the script has been successfully completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tTh2RI2ZKGoP"
   },
   "source": [
    "The ‘except’ block ensures that any errors that occur are caught and a corresponding error message is printed along with the exception details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXfDRLwNKPE4"
   },
   "source": [
    "Depending on the volume of images being downloaded the script may take a significant amount of time to complete. If downloading the dataset to Google Drive please allow additional time for the files to actually appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pxaiuYam5rAg"
   },
   "outputs": [],
   "source": [
    "# Export the dataset in YOLO format\n",
    "try:\n",
    "  dataset.export(\n",
    "    export_dir=export_dir,\n",
    "    dataset_type=fiftyone.types.YOLOv5Dataset,\n",
    "    label_field=\"detections\", # This field specifies where the relevant detection labels are stored\n",
    "    split='train'  # This line is optional unless specifically handling splits differently\n",
    "  )\n",
    "  print(\"Dataset exported successfully.\")\n",
    "except Exception as e:\n",
    "  print(f\"Error exporting dataset: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5frcJKhTWvpF"
   },
   "source": [
    "## Split the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frGHozsrTko6"
   },
   "source": [
    "### Download the Necessary Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Onj3ip6CToFc"
   },
   "source": [
    "In order to sort the dataset into a suitable training and validation split for model finetuning, certain Python libraries will need to be imported. This includes the `os`, `shutil`, `random`, and `logging` modules which provide various crucial functions for interacting with files and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ozOhKDhSS5r5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "155RmGg4Uhhv"
   },
   "source": [
    "This line of code configures the log that the script uses to keep track of events or changes that occur while the script is running. This specific logging format ensures that the following information is logged: when the event occurred, how important it was, and what the actual event or change was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BE78XtmyS1dW"
   },
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-M1m7CC5Y1TP"
   },
   "source": [
    "Here the paths are configured for the original dataset, as well as the destination files for the images and labels. When finetuning a YOLO model the following file organization is required:\n",
    "\n",
    "```\n",
    "# ├── dataset_directory\n",
    "│   ├── train\n",
    "│   │   ├── images\n",
    "│   │   │   ├── image1.jpg\n",
    "│   │   │   ├── image2.jpg\n",
    "│   │   │   └── ...\n",
    "│   │   └── labels\n",
    "│   │       ├── image1.txt\n",
    "│   │       ├── image2.txt\n",
    "│   │       └── ...\n",
    "│   ├── valid\n",
    "│   │   ├── images\n",
    "│   │   │   ├── image1.jpg\n",
    "│   │   │   ├── image2.jpg\n",
    "│   │   │   └── ...\n",
    "│   │   └── labels\n",
    "│   │       ├── image1.txt\n",
    "│   │       ├── image2.txt\n",
    "│   │       └── ...\n",
    "```\n",
    "It is crucial to ensure that the training and validation files follow this format, or else the finetuning script will not work.\n",
    "\n",
    "`validation_split_percentage = 0.2` ensures that 20% of the dataset is reserved for validation, while the remaining 80% will be used to train the model. This spit percentage can be modified according to the available data and specific requirements of the model, but 0.2 is the standard.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fsLOBsaBTRr0"
   },
   "outputs": [],
   "source": [
    "# Paths configuration\n",
    "dataset_path = '/content/drive/MyDrive/shared-data/Notebook datafiles/Finetuning-YOLOv5-animals/coco-dataset'\n",
    "train_path = '/content/drive/MyDrive/shared-data/Notebook datafiles/Finetuning-YOLOv5-animals/images/train'\n",
    "val_path = '/content/drive/MyDrive/shared-data/Notebook datafiles/Finetuning-YOLOv5-animals/images/val'\n",
    "train_labels_path = '/content/drive/MyDrive/shared-data/Notebook datafiles/Finetuning-YOLOv5-animals/labels/train'\n",
    "val_labels_path = '/content/drive/MyDrive/shared-data/Notebook datafiles/Finetuning-YOLOv5-animals/labels/val'\n",
    "validation_split_percentage = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RySH5hhuaq2M"
   },
   "source": [
    "The `os` module is then used to check that the previously defined directories exist using the `os.makedirs()` function. If the directories do not exist, they are then created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cRyzGN2hTTWH"
   },
   "outputs": [],
   "source": [
    "# Ensure target directories exist\n",
    "os.makedirs(train_path, exist_ok=True)\n",
    "os.makedirs(val_path, exist_ok=True)\n",
    "os.makedirs(train_labels_path, exist_ok=True)\n",
    "os.makedirs(val_labels_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1b5ceojJy6jg"
   },
   "source": [
    "### Define the Sorting Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxP2EWu7zh7C"
   },
   "source": [
    "This large code block defines the `sort_data` function for later use. It incorporates several error handling blocks to ensure graceful failure should there be something wrong with the files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XE-HeGjKbHRT"
   },
   "source": [
    "The `sort_data` function finds the images and their matching label files and randomly shuffles them using the random module imported at the beginning of the script. Then, the files are moved into separate directories for training and validation images and labels. An ‘if’ block is included to print a warning if any images are missing labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGb4D-0gd4eg"
   },
   "source": [
    "For large image datasets this script may take a longer period of time to execute in colab. If the dataset is being sorted into files on Google Drive (as it is in this example) it may take a longer period of time for the images and label files to actually appear in the directories once the script has completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8-PVGKMhTVC5"
   },
   "outputs": [],
   "source": [
    "# Function to sort data into train and validation sets\n",
    "def sort_data(dataset_path, train_path, val_path, train_labels_path, val_labels_path, val_split):\n",
    "    try:\n",
    "        images_path = os.path.join(dataset_path, 'images')\n",
    "        labels_path = os.path.join(dataset_path, 'labels')\n",
    "\n",
    "        image_extensions = ['.png', '.jpg', '.jpeg']\n",
    "        image_files = [f for f in os.listdir(images_path) if os.path.splitext(f)[1].lower() in image_extensions]\n",
    "        label_files = {os.path.splitext(f)[0] for f in os.listdir(labels_path) if f.lower().endswith('.txt')}\n",
    "\n",
    "        matching_files = [os.path.splitext(img)[0] for img in image_files if os.path.splitext(img)[0] in label_files]\n",
    "\n",
    "        random.shuffle(matching_files)\n",
    "        split_index = int(len(matching_files) * (1 - val_split))\n",
    "        train_images = matching_files[:split_index]\n",
    "        val_images = matching_files[split_index:]\n",
    "\n",
    "        missing_labels = [img + '.txt' for img in matching_files if img not in label_files]\n",
    "\n",
    "        for img in train_images:\n",
    "            for ext in image_extensions:\n",
    "                image_file = os.path.join(images_path, img + ext)\n",
    "                if os.path.exists(image_file):\n",
    "                    shutil.move(image_file, os.path.join(train_path, img + ext))\n",
    "                    break  # Break out of the loop once the correct extension is found\n",
    "\n",
    "            label_file = os.path.join(labels_path, img + '.txt')\n",
    "            if os.path.exists(label_file):\n",
    "                shutil.move(label_file, os.path.join(train_labels_path, img + '.txt'))\n",
    "            else:\n",
    "                logging.warning(f\"Label file not found: {label_file}\")\n",
    "\n",
    "        for img in val_images:\n",
    "            for ext in image_extensions:\n",
    "                image_file = os.path.join(images_path, img + ext)\n",
    "                if os.path.exists(image_file):\n",
    "                    shutil.move(image_file, os.path.join(val_path, img + ext))\n",
    "                    break  # Break out of the loop once the correct extension is found\n",
    "\n",
    "            label_file = os.path.join(labels_path, img + '.txt')\n",
    "            if os.path.exists(label_file):\n",
    "                shutil.move(label_file, os.path.join(val_labels_path, img + '.txt'))\n",
    "            else:\n",
    "                logging.warning(f\"Label file not found: {label_file}\")\n",
    "\n",
    "        if missing_labels:\n",
    "            logging.warning(\"Some images are missing label files.\")\n",
    "            logging.warning(f\"Missing labels: {missing_labels}\")\n",
    "        logging.info(\"Data sorted into training and validation directories\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5iDBZnnUd7Ug"
   },
   "source": [
    "### Sort the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_MRfQjKSzMwO"
   },
   "source": [
    "This block calls the previously defined `sort_data` function with several arguments consisting of the folder directories and validation split defined in an earlier module. When the script has finished sorting the dataset a message is printed to alert the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 98797,
     "status": "ok",
     "timestamp": 1718336811704,
     "user": {
      "displayName": "Ryleigh Bruce",
      "userId": "04866625339349492872"
     },
     "user_tz": 300
    },
    "id": "ryq-Z6c85POp",
    "outputId": "312388b3-112b-4c06-924c-dc2c7c2f9572"
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    sort_data(dataset_path, train_path, val_path, train_labels_path, val_labels_path, validation_split_percentage)\n",
    "\n",
    "print('Dataset has been sorted into training and validation folders.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EyXyefI5Xkz"
   },
   "source": [
    "## Creating a YAML File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9KVrX9dP0JK2"
   },
   "source": [
    "### Write the File Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSr7cTSh0f6m"
   },
   "source": [
    "In order to successfully train a YOLO model it is crucial to have an accurate .yaml file. This tells the model where to find the training and validation files, the number of classes, and what classes it is looking for. The classes **must** exactly match the ones in the dataset label files or else the model training will fail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijL9qB4X5dn2"
   },
   "source": [
    "The content of the .yaml file will be assigned in string format to the `yaml_content` variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "156Zg0tl3SJX"
   },
   "source": [
    "`train` and `val` are the paths for the training and validation **image** folders, respectively. If the directory structure specified in the ‘Splitting the Dataset’ section was followed correctly then the model will be able to find the corresponding label folders without the label folder paths being provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFC4DrPW3XMa"
   },
   "source": [
    "`nc` is the total number of classes contained in the dataset. In this example, a custom deer dataset has been aggregated with the coco dataset yielding a total of 80 classes. Despite this, in the label files the deer class is labeled as ‘79’ as the list of class names starts at ‘0’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hxMrLHKDNdWS"
   },
   "outputs": [],
   "source": [
    "yaml_content = \"\"\"\n",
    "train: /content/drive/MyDrive/shared-data/Notebook datafiles/Finetuning-YOLOv5-animals/images/train\n",
    "val: /content/drive/MyDrive/shared-data/Notebook datafiles/Finetuning-YOLOv5-animals/images/val\n",
    "nc: 80\n",
    "names: ['dog', 'person', 'bench', 'potted plant', 'dining table', 'cup', 'knife', 'spoon',\n",
    "        'cake', 'book', 'umbrella', 'handbag', 'bird', 'cell phone', 'car', 'tie', 'backpack',\n",
    "        'traffic light', 'teddy bear', 'chair', 'clock', 'parking meter', 'elephant', 'cow',\n",
    "        'boat', 'skateboard', 'baseball bat', 'baseball glove', 'bottle', 'truck', 'couch',\n",
    "        'tennis racket', 'sports ball', 'fork', 'vase', 'zebra', 'horse', 'train', 'surfboard',\n",
    "        'bus', 'fire hydrant', 'frisbee', 'suitcase', 'cat', 'bowl', 'bicycle', 'motorcycle',\n",
    "        'airplane', 'tv', 'stop sign', 'laptop', 'wine glass', 'microwave', 'sink',\n",
    "        'refrigerator', 'giraffe', 'sheep', 'broccoli', 'banana', 'oven', 'apple', 'orange',\n",
    "        'kite', 'snowboard', 'remote', 'pizza', 'bed', 'skis', 'donut', 'sandwich', 'hot dog',\n",
    "        'bear', 'toaster', 'scissors', 'toilet', 'toothbrush', 'carrot', 'mouse', 'keyboard',\n",
    "        'deer']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b848t3h90aEG"
   },
   "source": [
    "`yaml_path` is simply the path to where the finished .yaml file will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lgq9C9E60Ryi"
   },
   "outputs": [],
   "source": [
    "# Change this path to where you want to save the YAML file in your Google Drive\n",
    "yaml_path = '/content/drive/MyDrive/shared-data/Notebook datafiles/Finetuning-YOLOv5-animals/coco-deer-training.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5I2lynT0Zny"
   },
   "source": [
    "The script begins by opening a file at the path defined in the `yaml_path` variable using the `open()` function. The `‘w’` in the argument indicates that the file has been opened for writing, and the file object is assigned to the `f` variable. `f.write(yaml_content)` calls the object f to write the `yaml_content` string to the opened file. The file is automatically closed once the ‘with’ block is exited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-oOmvmqz5rRa"
   },
   "source": [
    "Once the file is closed a print statement indicates where the .yaml file has been saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5azxG3z0YFk"
   },
   "outputs": [],
   "source": [
    "with open(yaml_path, 'w') as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(f\"YAML file saved to {yaml_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xz2INMzLWw2i"
   },
   "source": [
    "### Check the YAML File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dXc_ORo5vHC"
   },
   "source": [
    "If desired, the .yaml file can be loaded in order to check its contents. First the `yaml` library must be imported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gxBqNx_7Ydb"
   },
   "source": [
    "The `open()` function is used again to open a file at the `yaml_path`, but rather than creating a new file it opens the newly created .yaml file. The `‘r’` specifies that the file has been opened for reading, and `as f` creates a file object f. `yaml.safe_load` reads the content of the file and converts it to a Python dictionary or a list (depending on the file contents). The `safe_load` method ensures that only simple Python objects are allowed, preventing potentially dangerous .yaml files from being opened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 220,
     "status": "ok",
     "timestamp": 1718336987173,
     "user": {
      "displayName": "Ryleigh Bruce",
      "userId": "04866625339349492872"
     },
     "user_tz": 300
    },
    "id": "Lo7FWzodAAhI",
    "outputId": "ca84b8ba-c476-473b-ec52-d4390da4e9fd"
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(yaml_path, 'r') as f:\n",
    "    loaded_yaml = yaml.safe_load(f)\n",
    "print(loaded_yaml)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM5oinGodOpM0fQ8t4atnSp",
   "collapsed_sections": [
    "rNDYJwYIKmw-",
    "CO8v6QZr5hW1",
    "7Y5nb3B3DcPT",
    "iJijH1Uv8FQP",
    "Cj7ALFQA8FgB",
    "5frcJKhTWvpF",
    "6EyXyefI5Xkz",
    "9KVrX9dP0JK2"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
