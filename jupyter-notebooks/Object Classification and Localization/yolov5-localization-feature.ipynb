{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/umanitoba-meagher-projects/public-experiments/blob/main/jupyter-notebooks/Object%20Classification%20and%20Localization/yolov5-localization-feature.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LC9v7vWHXseM"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Ryleigh J. Bruce\n",
    "Date: June 18, 2024\n",
    "\n",
    "Purpose:To load and implement the object localization feature of the YOLOv5 model.\n",
    "\n",
    "\n",
    "Note: The author generated this text in part with GPT-4,\n",
    "OpenAI’s large-scale language-generation model. Upon generating\n",
    "draft code, the authors reviewed, edited, and revised the code\n",
    "to their own liking and takes ultimate responsibility for\n",
    "the content of this code.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook demonstrates the implementation of object localization using the YOLOv5 model. It begins with dataset preparation, including downloading datasets from the FiftyOne Data Zoo. The notebook then proceeds to install necessary libraries, clone the YOLOv5 repository, and load a pre-trained YOLOv5 model. Key functionalities include defining custom functions for predictions, annotating images, and visualizing results. The methodologies employed ensure efficient handling of datasets, seamless integration with machine learning workflows, and adaptability for various use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critical Uses & Adaptability\n",
    "\n",
    "### What the Notebook Can Be Used For:\n",
    "**Dataset Exploration:** This notebook enables users to explore datasets by downloading and preparing them for object detection tasks. The dataset preparation steps in the code blocks for mounting Google Drive and downloading datasets provide a structured approach to handling datasets.\n",
    "\n",
    "**Educational Purposes & Demonstrations:** The notebook provides a step-by-step guide to using Python scripts and machine learning libraries for image processing. It educates readers on the practical application of YOLOv5 for object detection, with detailed instructions in the code blocks for installing libraries, cloning the YOLOv5 repository, and loading the model.\n",
    "\n",
    "### How the Notebook Can Be Adapted:\n",
    "**Integration with Spatial Design & Architectural Studies:** The object detection capabilities of this notebook can be applied to site analysis in architectural or spatial datasets. The code blocks for processing and annotating images are particularly relevant for such applications.\n",
    "\n",
    "**Variables & Customization:** Users can modify variables such as input and output directories, font sizes, and model parameters to tailor the workflow to their specific needs. The code blocks defining `input_folder_path`, `output_folder_path`, and `process_images_in_folder` provide clear examples of how to customize these variables.\n",
    "\n",
    "**Swapping Datasets:** The notebook allows users to replace the dataset with custom datasets by modifying the dataset loading and preparation steps. The code block for loading datasets using `fiftyone.zoo.load_zoo_dataset` demonstrates how to swap datasets effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ysby5TACXykc"
   },
   "source": [
    "## Module: Mount the Notebook to Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGp2ucNEXzTI"
   },
   "source": [
    "Here we import the drive module that allows us to link the Colab environment with our google drive, where the desired data set is stored. This allows us to access any files located within Google Drive and interact with them directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2282,
     "status": "ok",
     "timestamp": 1718726051742,
     "user": {
      "displayName": "Ryleigh Bruce",
      "userId": "04866625339349492872"
     },
     "user_tz": 300
    },
    "id": "PVw0HLGgtRUY",
    "outputId": "7307ec5c-5ffa-4efa-ab3e-156f7fa4efd9"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CO8v6QZr5hW1"
   },
   "source": [
    "# Downloading a Dataset from FiftyOne Data Zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkPFTzy38Etn"
   },
   "source": [
    "First the FiftyOne library must be installed in the colab environment. This is done using the `!pip install` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 59148,
     "status": "ok",
     "timestamp": 1718662239542,
     "user": {
      "displayName": "Ryleigh Bruce",
      "userId": "04866625339349492872"
     },
     "user_tz": 300
    },
    "id": "a0rYckXuPGC5",
    "outputId": "7258c136-e51f-437f-a1e8-c86d1ac0da38"
   },
   "outputs": [],
   "source": [
    "!pip install fiftyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJSDdaxU7948"
   },
   "outputs": [],
   "source": [
    "import fiftyone\n",
    "import fiftyone.zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y4JxE4lC8AIV"
   },
   "outputs": [],
   "source": [
    "export_dir = \"/content/drive/MyDrive/shared-data/Notebook datafiles/Street-view-datasets/Geo-dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 8527,
     "status": "ok",
     "timestamp": 1718662732510,
     "user": {
      "displayName": "Ryleigh Bruce",
      "userId": "04866625339349492872"
     },
     "user_tz": 300
    },
    "id": "HJ1AYydL5mWM",
    "outputId": "49fd6a3f-3ac9-42c4-e640-6e8820f50ffe"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Step 3: Load the dataset\n",
    "    dataset = fiftyone.zoo.load_zoo_dataset(\"quickstart-geo\")\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "\n",
    "    # Step 4: Export the dataset to the specified directory on Google Drive\n",
    "    dataset.export(\n",
    "        export_dir=export_dir,\n",
    "        dataset_type=fiftyone.types.FiftyOneDataset  # You can specify other supported formats as needed\n",
    "    )\n",
    "    print(f\"Dataset exported to Google Drive at: {export_dir}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pxaiuYam5rAg"
   },
   "outputs": [],
   "source": [
    "# Export the dataset in YOLO format\n",
    "try:\n",
    "  dataset.export(\n",
    "    export_dir=export_dir,\n",
    "    dataset_type=fiftyone.types.YOLOv5Dataset,\n",
    "    label_field=\"detections\", # This field specifies where the relevant detection labels are stored\n",
    "    split='train'  # This line is optional unless specifically handling splits differently\n",
    "  )\n",
    "  print(\"Dataset exported successfully.\")\n",
    "except Exception as e:\n",
    "  print(f\"Error exporting dataset: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tuz2AicB-Ump"
   },
   "source": [
    "# Using the Pre-trained YOLOv5 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feLMBno_LDWT"
   },
   "source": [
    "## Module: Loading the YOLOv5 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0YgrYjhJKu3"
   },
   "source": [
    "In order to install and use the pre-trained YOLOv5 model, the `tensorflow` and `pillow` (PIL) libraries must be installed using the `!pip` package installer. `tensorflow` is an open-source machine learning library used for machine learning tasks and PIL allows scripts to open,manipulate, and save various image formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 8474,
     "status": "ok",
     "timestamp": 1718726062769,
     "user": {
      "displayName": "Ryleigh Bruce",
      "userId": "04866625339349492872"
     },
     "user_tz": 300
    },
    "id": "3ttNR3lxqVrA",
    "outputId": "6d9b71e0-2c63-498e-984c-f248d52ad6d3"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "glQTkq-dLBwY"
   },
   "source": [
    "The `os` and `shutil` modules are both critical for higher level file operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ASMhGXL8Lpxq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1kXgTBvNTGq"
   },
   "source": [
    "The ‘if’ block begins by using the `os` module to check if the `/content/yolov5` path already exists on the file system, and if the condition evaluates to True then the `shutil` module is used to delete the directory to prevent potential error messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fLDTiJmiLqIE"
   },
   "outputs": [],
   "source": [
    "# If the yolov5 directory already exists, remove it to avoid conflicts\n",
    "if os.path.exists('/content/yolov5'):\n",
    "    shutil.rmtree('/content/yolov5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eOZrvpnqUcxg"
   },
   "source": [
    "Here the `!git` command from the Git version control system used to copy the YOLOv5 repository from the GitHub server and clone it into the specified directory on the local machine (in this case the path for the directory is `/content/yolov5`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P2XGn8u8LtGK"
   },
   "outputs": [],
   "source": [
    "# Clone YOLOv5 repository\n",
    "!git clone https://github.com/ultralytics/yolov5 /content/yolov5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEX_VSbpYFRb"
   },
   "source": [
    "This line of code uses the `%` magic command unique to Jupyter Notebooks. `cd` changes the current working directory in the notebook environment to the directory specified in the file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5BUytSHLuzW"
   },
   "outputs": [],
   "source": [
    "# Change directory to the cloned YOLOv5 repo\n",
    "%cd /content/yolov5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlFhBADoem6W"
   },
   "source": [
    "`git pull` updates the local repository with the latest changes from the remote repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0gqM7M_LwSa"
   },
   "outputs": [],
   "source": [
    "# Pull the latest changes\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lI9kNyesenYo"
   },
   "source": [
    "Here the `!pip` installer is used to install several required packages. The first line uses `-r` to tell pip to install all of the packages listed in the `requirements.txt` file. The `ultralytics`  and `torch`, `torchvision`, and `torchaudio` packages are then installed using the `--quiet` command to ensure only essential information is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_XW_w04bLx1r"
   },
   "outputs": [],
   "source": [
    "# Install the required packages\n",
    "!pip install -r requirements.txt\n",
    "!pip install ultralytics --quiet\n",
    "!pip install torch torchvision torchaudio --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ArZEupfbenpy"
   },
   "source": [
    "Next the `torch`, `pillow`, `os`, and `pandas` modules must be imported for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zWp9tXFYLzOd"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vf9gLpg4en36"
   },
   "source": [
    "Here the `torch.hub.load` function is used to load the YOLOv5 model from the specified directory. Since there are multiple versions of the YOLOv5 model, the second argument specifies that the YOLOv5s variant should be loaded.`pretrained=True` indicates that  a pre trained version of the YOLOv5s model should be loaded into the model variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUYNp-E4dG18"
   },
   "source": [
    "The `torch.cuda.is_available()` function checks if a CUDA-compatible GPU is available on the local machine, and returns ‘cuda’ if GPU is available (otherwise returning ‘cpu’). Appending `.eval` to the end of the function sets the model into evaluation mode to ensure that it behaves correctly when making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wmpY93SfL14e"
   },
   "outputs": [],
   "source": [
    "# Load the YOLOv5 model from Torch Hub\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "model.to('cuda' if torch.cuda.is_available() else 'cpu').eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGlqREUEeoVz"
   },
   "source": [
    "This line of code determines the names of the classes available for detection through the loaded YOLOv5s model and stores them in the `class_names` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-MAzQFhL2lv"
   },
   "outputs": [],
   "source": [
    "# Get class names directly from the model\n",
    "class_names = model.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyVnVLctL5PE"
   },
   "source": [
    "## Module: Implementing the Object Localization Feature on a Dataset of Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUqXnHuKeCD5"
   },
   "source": [
    "Several functions must be defined before the YOLOv5 model can be used to generate a series of predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t31M4Te-hiRs"
   },
   "source": [
    "The `get_predictions` function defined below begins with a ‘try’ block that takes an image and converts it to the RGB color space and stores the result in the `img` variable. The ‘except’ block ensures that if there are any errors with opening the file a corresponding error message is printed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4vlNCU1ht06"
   },
   "source": [
    "`results = model(img)` uses the model to process the information stored in the `img` variable and stores the raw detection results in the `results` variable for further processing. The information is then converted into a dataframe with bounding box coordinates using the `Pandas` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VxUQ-BChz9r"
   },
   "source": [
    "`predictions = []` initializes an empty list to store the analyzed prediction results. The script then iterates through each row of the dataframe to retrieve the class name, detection confidence, and bounding box coordinates, and then adds a tuple containing this information to the `predictions` list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzeVeQY1h9ZG"
   },
   "source": [
    "The final line of the code block returns the completed `predictions` list for each detected object in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X6vPl8MSdyK9"
   },
   "outputs": [],
   "source": [
    "def get_predictions(img_path):\n",
    "    try:\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "    except IOError:\n",
    "        print(f\"Error: Could not open {img_path}\")\n",
    "        return []\n",
    "    results = model(img)\n",
    "    results = results.pandas().xyxy[0]\n",
    "    predictions = []\n",
    "    for _, row in results.iterrows():\n",
    "        class_name = class_names[int(row['class'])]\n",
    "        conf = row['confidence']\n",
    "        bbox = [int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])]\n",
    "        predictions.append((class_name, conf, bbox))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUS1GZHXeCn3"
   },
   "source": [
    "Next the `draw_text_with_outline` function must be defined to ensure the images have legible prediction labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5I_uMtX2lHF5"
   },
   "source": [
    "The function contains several parameters: `draw` (used to draw on images), `position` (a tuple containing the x, y coordinates of where the text should be drawn), `text` (the string to be drawn), `font` (the font used for the label), `text_color` (the color of the main text), `outline_color` (the color of the text outline), and `outline_width` (the width of the outline in pixels). `x, y = position` decomposes the position tuple into x and y coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLt0724HlSWq"
   },
   "source": [
    "The ‘for’ loop draws the text at slightly offset positions to create an outline effect around the main text, making it more legible in different image lighting and environmental conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-q8A2WFlVAU"
   },
   "source": [
    "The `draw.text((x, y)..)` function draws the main text at the specified `x, y` coordinates on top of the outline using text_color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2AbzsYzEd0R7"
   },
   "outputs": [],
   "source": [
    "def draw_text_with_outline(draw, position, text, font, text_color, outline_color, outline_width):\n",
    "    x, y = position\n",
    "    # Draw the outline by drawing text in the outline_color slightly offset in each direction\n",
    "    for offset in range(-outline_width, outline_width + 1):\n",
    "        draw.text((x + offset, y), text, font=font, fill=outline_color)\n",
    "        draw.text((x - offset, y), text, font=font, fill=outline_color)\n",
    "        draw.text((x, y + offset), text, font=font, fill=outline_color)\n",
    "        draw.text((x, y - offset), text, font=font, fill=outline_color)\n",
    "\n",
    "    # Draw the text in the center in text_color\n",
    "    draw.text((x, y), text, font=font, fill=text_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0x-V0PiAeDIm"
   },
   "source": [
    "The final function that must be defined before making predictions with the YOLO model is the `process_images_in_folder` function.This allows the function to process all the images in a given directory while gracefully handling any potential errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPit7KHkozFp"
   },
   "source": [
    "The function begins by listing the acceptable image extensions in the `img_exts` list. Then the script checks if the output directory already exists, and uses the `os` module to create one if it doesn’t."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bajUGPIZo3ZW"
   },
   "source": [
    "A ‘for’ loop iterates over each file in the input folder and checks that each image has a valid extension (one of the extensions listed in the `img_exts` variable). If it encounters a file with an invalid extension then the file is skipped over. The function then uses the `os` module to check the file paths of the images with valid extensions to ensure they are indeed files. The previously defined `get_predictions()` function is then called to get predictions for each image. If predictions are found it proceeds to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4lQi8Gxo-if"
   },
   "source": [
    "The ‘try’ block begins by opening the image and converting it to the RGB color space. A specific font in the specified size can then be loaded into the `font` variable, but the script returns to the default font should any errors occur. Another ‘for’ block then loops through each prediction, drawing a rectangle around the detected object and adding text annotations. The function then saves the annotated image to the output folder with a modified filename prefixed with ‘annotated-”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAjyWARvpJFt"
   },
   "source": [
    "The `IOError` catches and handles any potential issues with opening or saving images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yyGNT1jDpMN6"
   },
   "source": [
    "The function then alerts the user when it has finished processing and saving all of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--yQTYruqLf_"
   },
   "outputs": [],
   "source": [
    "def process_images_in_folder(input_folder_path, output_folder_path):\n",
    "    # List of acceptable image extensions\n",
    "    img_exts = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif', '.ico']\n",
    "\n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path)\n",
    "\n",
    "    for filename in os.listdir(input_folder_path):\n",
    "        if not any(filename.lower().endswith(ext) for ext in img_exts):  # Check if the file is an image.\n",
    "            continue  # Skip the current iteration if the file is not an image.\n",
    "        img_path = os.path.join(input_folder_path, filename)\n",
    "        if os.path.isfile(img_path):\n",
    "            predictions = get_predictions(img_path)\n",
    "            if predictions:\n",
    "                try:\n",
    "                    img = Image.open(img_path).convert('RGB')\n",
    "                    draw = ImageDraw.Draw(img)\n",
    "\n",
    "                    # Define font size and font\n",
    "                    font_size = 12  # Adjust this value as needed\n",
    "                    try:\n",
    "                        font = ImageFont.truetype(\"arial.ttf\", font_size)\n",
    "                    except IOError:\n",
    "                        font = ImageFont.load_default()  # Fallback to default font in case of error\n",
    "\n",
    "                    for class_name, conf, bbox in predictions:\n",
    "                        draw.rectangle(bbox, outline='red', width=2)\n",
    "                        draw_text_with_outline(draw, (bbox[0], bbox[1]), f'{class_name} {conf:.2f}', font, 'white', 'red', 2)\n",
    "\n",
    "                    output_path = os.path.join(output_folder_path, f'annotated-{filename}')\n",
    "                    img.save(output_path)\n",
    "                    print(f'Processed {filename}. Annotated image saved.')\n",
    "                except IOError:\n",
    "                    print(f\"Error: Could not process {img_path}\")\n",
    "\n",
    "    print(f\"All images processed. Annotations saved in {output_folder_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGJ0uVNxeDtw"
   },
   "source": [
    "The following code block defines the input and output directories to be used in the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4RfWk-Nud9Bm"
   },
   "outputs": [],
   "source": [
    "# Paths to your folders\n",
    "input_folder_path = '/content/drive/MyDrive/shared-data/Notebook datafiles/Street-view-datasets/Geo-dataset/data'  # Path where images are stored\n",
    "output_folder_path = '/content/drive/MyDrive/shared-data/Notebook datafiles/Street-view-datasets/Geo-dataset/pre-trained-anno-2'  # Path where to save images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87e_qMvceEDh"
   },
   "source": [
    "This final line calls the `process_images_in_folder()` function with the input and output folders as its arguments. This results in the script getting predictions and annotating each image in the input directory, then saving the annotated images to the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 252360,
     "status": "ok",
     "timestamp": 1718726668837,
     "user": {
      "displayName": "Ryleigh Bruce",
      "userId": "04866625339349492872"
     },
     "user_tz": 300
    },
    "id": "qZC7W0QkqORQ",
    "outputId": "dbaad1e3-f2a6-4a6c-93ff-927cb1d19d6e"
   },
   "outputs": [],
   "source": [
    "# Process images\n",
    "process_images_in_folder(input_folder_path, output_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "492cgYUYWLkN"
   },
   "source": [
    "## Module: Visualizing a Subset of the Annotated Images for Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndIRwU_AqUiT"
   },
   "source": [
    "Importing the following libraries will enable the script to display a random subset of the newly annotated images.The Plotly Express (`plotly.express`) module is particularly useful for creating interactive visualizations such as the ones generated in this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5mVtXThOqBe7"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEY-4E2EqU6d"
   },
   "source": [
    "The `load_image` function loads an image from the specified file path and converts it to a NumPy array. The image is then opened and assigned to the `img` variable using a context manager to ensure that it is properly closed after the block of code is executed, even if any errors occur. The image is then converted to a three-dimensional NumPy array and returned at the end of the code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rp6OVruTqCRj"
   },
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    \"\"\"Load an image from a file path.\"\"\"\n",
    "    with Image.open(image_path) as img:\n",
    "        return np.array(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cauDL6OxqVPV"
   },
   "source": [
    "The `interactive_visualization` function begins by creating a list of the valid file names in the specified directory, and then filters them to only include image files ending in .png, .jpg, or .jpeg. The ‘if’ block ensures that there are images within the directory after which the `random` module is used to select a subset of images and store them in the `selected_files_subset` variable. The subset of images is then displayed with the image names as the plot titles using the `Plotly` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eDUzqe2fqG1X"
   },
   "outputs": [],
   "source": [
    "def interactive_visualization(directory, subset_size=4): #the subset value can be modified according to the desired number of images\n",
    "    # Getting the list of image file names that ends with the specified extensions\n",
    "    image_files = [file for file in os.listdir(directory) if file.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    if not image_files:\n",
    "        print(\"No images found in the directory.\")\n",
    "        return\n",
    "\n",
    "    # Select a subset of images from the list of image files\n",
    "    selected_files_subset = random.sample(image_files, min(subset_size, len(image_files)))\n",
    "\n",
    "    # Display selected images using Plotly\n",
    "    for image_file in selected_files_subset:\n",
    "        image_path = os.path.join(directory, image_file)\n",
    "        image = load_image(image_path)\n",
    "        fig = px.imshow(image)\n",
    "        fig.update_layout(title_text=f'Selected Image: {image_file}', margin=dict(l=10, r=10, t=40, b=10))\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oStgbjtOqVzp"
   },
   "source": [
    "The `interactive_visualization` function is then called with the annotated image directory as the argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1Ul-0vR2PGNPzIENHE3F7UzL7KgGkF5wS"
    },
    "executionInfo": {
     "elapsed": 17010,
     "status": "ok",
     "timestamp": 1718730721553,
     "user": {
      "displayName": "Ryleigh Bruce",
      "userId": "04866625339349492872"
     },
     "user_tz": 300
    },
    "id": "HtngepZuWcx-",
    "outputId": "f3aa8d5a-8c96-48b2-86aa-9664bc19f502"
   },
   "outputs": [],
   "source": [
    "interactive_visualization('/content/drive/MyDrive/shared-data/Notebook datafiles/Street-view-datasets/Geo-dataset/pre-trained-anno-2')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ysby5TACXykc",
    "CO8v6QZr5hW1",
    "feLMBno_LDWT",
    "NyVnVLctL5PE"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}