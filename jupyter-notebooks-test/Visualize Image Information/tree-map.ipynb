{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/umanitoba-meagher-projects/public-experiments/blob/main/jupyter-notebooks/Visualize%20Image%20Information/tree-map.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Yl9j7lxo5gc"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Author: Ryleigh J. Bruce\n",
        "Date: June 10, 2024\n",
        "\n",
        "Purpose: To generate a treemap to compare the volume of sightings across animal species and seasons\n",
        "\n",
        "\n",
        "Note: The author generated this text in part with GPT-4,\n",
        "OpenAI\u2019s large-scale language-generation model. Upon generating\n",
        "draft code, the authors reviewed, edited, and revised the code\n",
        "to their own liking and takes ultimate responsibility for\n",
        "the content of this code.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\n",
        "\n",
        "This Jupyter Notebook is designed to generate treemaps that visualize the volume of animal sightings across different species and seasons. The notebook begins by importing and preparing the necessary libraries and datasets, followed by data manipulation to group and summarize the information. It then creates treemaps to represent the data visually, both as a single comprehensive treemap and as individual treemaps for each season. The methodology involves using Python libraries such as `pandas` for data manipulation, `matplotlib` for visualization, and `squarify` for treemap generation. The notebook also includes functionality to filter data by location and season, normalize sizes for visualization, and assign unique colors to species for clarity. Additionally, it provides a legend for better interpretability and adjusts plot dimensions dynamically based on the dataset. This notebook is beneficial for analyzing patterns in animal sightings, understanding seasonal variations, and presenting data in an accessible visual format. It is structured to be modular, allowing users to adapt it for different datasets or purposes, making it a versatile tool for data exploration and visualization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Critical Uses & Adaptability\n",
        "\n",
        "### What the Notebook Can Be Used For:\n",
        "\n",
        "- **Dataset Exploration:**  \n",
        "  This notebook provides a structured approach to exploring datasets by grouping, summarizing, and visualizing data. It is particularly useful for identifying patterns, trends, and outliers in animal sightings across species and seasons.\n",
        "\n",
        "- **Educational Purposes & Demonstrations:**  \n",
        "  The notebook serves as an educational resource for demonstrating the use of Python in data analysis and visualization. It introduces readers to libraries like `pandas`, `matplotlib`, and `squarify`, and showcases how machine learning-adjacent techniques can be applied to work with image-related datasets.\n",
        "\n",
        "- **Feature Extraction:**  \n",
        "  By grouping data and visualizing it in treemaps, the notebook aids in extracting key features such as the most frequently sighted species or seasonal trends. These insights can be used for further analysis or decision-making.\n",
        "\n",
        "### How the Notebook Can Be Adapted:\n",
        "\n",
        "- **Integration with Spatial Design & Architectural Studies:**  \n",
        "  The notebook can be adapted for site analysis in spatial design and architecture by replacing the dataset with location-based data. For example, it could visualize the distribution of vegetation, wildlife, or human activity across a site.\n",
        "\n",
        "- **Variables & Customization:**  \n",
        "  - The notebook's variables, such as `location_id` and `Season`, can be modified to focus on specific subsets of data.  \n",
        "  - Users can adjust the figure size, color schemes, and normalization parameters in the plotting sections (e.g., `squarify.plot()` in the cell with ID `8c691b91`) to suit their visualization needs.\n",
        "\n",
        "- **Swapping Datasets:**  \n",
        "  - The dataset can be replaced by modifying the file path in the cell that loads the data (`0960df8f` for single treemaps or `75c3c4e3` for seasonal treemaps).  \n",
        "  - Users can adapt the notebook to work with different datasets, such as those containing image metadata, by ensuring the new dataset has compatible columns or adjusting the code accordingly.\n",
        "\n",
        "- **Scalability:**  \n",
        "  The notebook is scalable for larger datasets or more complex analyses. For instance, additional grouping criteria can be added to the `groupby()` function, or the visualization can be extended to include interactive plots using libraries like `plotly`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_5YYXzbo5JJ"
      },
      "source": [
        "## Module: Mount the Notebook to Google Drive and Install Necessary Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQdI9DASpGim"
      },
      "source": [
        "Here the drive module is imported, allowing the Colab environment to access files within Google Drive. The notebook is then mounted to Google Drive so that it can interact with the files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1938,
          "status": "ok",
          "timestamp": 1718222370507,
          "user": {
            "displayName": "Ryleigh Bruce",
            "userId": "04866625339349492872"
          },
          "user_tz": 300
        },
        "id": "YxhyHo0Kc8Yu",
        "outputId": "0cccc633-6b29-454c-f824-043e25bccf56"
      },
      "outputs": [],
      "source": [
        "# Borealis API configuration\nimport requests\nimport zipfile\n\nBOREALIS_SERVER = \"https://borealisdata.ca\"\n\ndef get_public_dataset_info(persistent_id):\n    \"\"\"\n    Get information about a public dataset\n    \"\"\"\n    url = f\"{BOREALIS_SERVER}/api/datasets/:persistentId/\"\n    params = {\"persistentId\": persistent_id}\n\n    response = requests.get(url, params=params)\n\n    if response.status_code == 200:\n        dataset_info = response.json()\n    else:\n        print(f\"Cannot access dataset: {response.status_code}\")\n        return None\n    \"\"\"\n    Get a list of files in a public dataset\n    \"\"\"\n    # Access the list of files from the dataset_info dictionary\n    files_list = dataset_info['data']['latestVersion']['files']\n\n    # Create an empty list to store file information\n    file_info_list = []\n\n    # Iterate through the files list and append file ID and filename to the list\n    for file_info in files_list:\n        file_id = file_info['dataFile']['id']\n        filename = file_info['dataFile']['filename']\n        file_info_list.append({\"file_id\": file_id, \"filename\": filename})\n\n    return file_info_list\n\ndef download_public_file(file_id, save_path=\"./\"):\n    \"\"\"\n    Download a specific public file from a dataset by its file ID\n    No authentication required\n    \"\"\"\n    url = f\"{BOREALIS_SERVER}/api/access/datafile/{file_id}\"\n\n    response = requests.get(url, stream=True)\n\n    if response.status_code == 200:\n        # Determine filename from headers or URL\n        filename = None\n        if \"Content-Disposition\" in response.headers:\n            cd = response.headers[\"Content-Disposition\"]\n            # Try to extract filename from content disposition\n            if \"filename=\" in cd:\n                filename = cd.split(\"filename=\")[1].strip('\"')\n\n        # Fallback to extracting from URL if header not available or malformed\n        if not filename:\n             filename = url.split(\"/\")[-1]\n\n        file_path = f\"{save_path}/{filename}\"\n\n        with open(file_path, 'wb') as f:\n            for chunk in response.iter_content(chunk_size=8192):\n                f.write(chunk)\n\n        print(f\"SUCCESS: File downloaded to {file_path}\")\n        return file_path\n    else:\n        print(f\"ERROR: {response.status_code}: File may be restricted or not found\")\n        return None\n\ndef is_zip_file(filepath):\n    \"\"\"\n    Checks if a file is a valid zip file.\n    \"\"\"\n    return zipfile.is_zipfile(filepath)\n\ndef unzip_file(filepath, extract_path=\"./\"):\n    \"\"\"\n    Unzips a zip file to a specified path and returns the name of the top-level extracted folder.\n    Returns None if not a zip file or extraction fails.\n    \"\"\"\n    if is_zip_file(filepath):\n        try:\n            with zipfile.ZipFile(filepath, 'r') as zip_ref:\n                # Get the name of the top-level directory within the zip\n                # Assumes there is a single top-level directory\n                top_level_folder = None\n                for file_info in zip_ref.infolist():\n                    parts = file_info.filename.split('/')\n                    if parts[0] and len(parts) > 1:\n                        top_level_folder = parts[0]\n                        break # Assuming the first entry gives the top-level folder\n\n                zip_ref.extractall(extract_path)\n                print(f\"SUCCESS: Successfully unzipped {filepath} to {extract_path}\")\n                return top_level_folder\n\n        except Exception as e:\n            print(f\"ERROR: Error unzipping {filepath}: {e}\")\n            return None\n    else:\n        print(f\"INFO: {filepath} is not a valid zip file.\")\n        return None\n\n# Initialize Borealis dataset access\npublic_doi = \"doi:10.5683/SP3/H3HGWF\"\nprint(\"Borealis dataset initialized for animal notebook data.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtonPQcwk3Nv"
      },
      "source": [
        "This module imports the `pandas`, `matplotlib`, `squarify`, and `numpy` libraries. The `pandas` library is crucial for data manipulation, and `matplotlib` is a plotting library that allows various visualizations to be created in Python. `Squarify` is a specialized library to create treemaps and `numpy` is useful for handling arrays and other aspects of numerical computing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGW8WhzG2qkx"
      },
      "outputs": [],
      "source": [
        "!pip install squarify\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import squarify\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ljq48eDTKlU"
      },
      "source": [
        "# Creating a Single Treemap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n26ppiTZ2rRK"
      },
      "source": [
        "## Module: Create a DataFrame Using the Excel File"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPn1zM8VlS3Q"
      },
      "source": [
        "This line of code loads the provided Excel file and loads it into a two-dimensional DataFrame, a data format consisting of rows and columns.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6ai_wbD22Wt"
      },
      "outputs": [],
      "source": [
        "# Load the data into a Pandas dataframe\n",
        "df = pd.read_excel(\"./combined_animals.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVX6cVi9m8Th"
      },
      "source": [
        "Here the `groupby()` function is used to group the rows within the DataFrame by the values in the `SpeciesList` column. This means that all rows containing the same species name are grouped. `[\u201cSpeciesCount\u201d].sum` calculates the sum of all of the values within the `SpeciesCount` column for each species group. The final portion of this line, `.reset_index()`, resets the index of the DataFrame and returns the `SpeciesList` to a column from its grouped state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sah58rmDm8nr"
      },
      "outputs": [],
      "source": [
        "# Summarize the data for the treemap\n",
        "species_counts = df.groupby(\"SpeciesList\")[\"SpeciesCount\"].sum().reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtIKzIm_nAYl"
      },
      "source": [
        "Here the DataFrame is sorted based on the values in the `SpeciesCount` column. `ascending=False` ensures that the values are sorted in descending order, to ensure that the most significant categories will be seen first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbNgyZQRnAva"
      },
      "outputs": [],
      "source": [
        "# Sort the data for better visualization\n",
        "species_counts = species_counts.sort_values(by=\"SpeciesCount\", ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npVRYLnF23XL"
      },
      "source": [
        "## Module: Prepare the Values to be Plotted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "772SUqHunetb"
      },
      "source": [
        "The `squarify.normalize_sizes()` function normalizes the size of the rectangles to be used in the treemap. The `100,100` values represent the width and height of the treemap layout."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YulClo1MndJc"
      },
      "outputs": [],
      "source": [
        "# Normalize sizes\n",
        "sizes = squarify.normalize_sizes(species_counts[\"SpeciesCount\"], 100, 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YhtFtx4ne-y"
      },
      "source": [
        "`num_categories = len(species_counts)` counts and returns the number of rows in the species_counts DataFrame and stores it in the `num_categories` variable. This value is then used to determine the number of unique colors that must be stored in the `colors` variable. These colors are drawn from a pre-existing colormap called `tab20c` which is called using the `plt.get_cmap() function`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ji2w_gqa25GE"
      },
      "outputs": [],
      "source": [
        "# Create a colormap\n",
        "num_categories = len(species_counts)\n",
        "colors = plt.get_cmap('tab20c')(np.linspace(0, 1, num_categories))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPUEqlGO27ei"
      },
      "source": [
        "## Module: Create the Figure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C4zViycplLr"
      },
      "source": [
        "Here the `matplotlib` library is used to create a new figure and set of subplots. The size is specified using `figsize=(12, 8)` which means that the created figure will be 12 inches wide and 8 inches tall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzTzPtlEwyju"
      },
      "source": [
        "`squarify.plot()` creates the treemap plot using the normalized rectangles and the colors determined in previous modules, while the `ax=ax` and `pad=True` parameters enhance plot legibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WJWV2aBpf__"
      },
      "outputs": [],
      "source": [
        "# Create a squarify plot\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "squarify.plot(sizes=sizes,\n",
        "              color=colors,\n",
        "              alpha=.8,\n",
        "              ax=ax,\n",
        "              pad=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTAjk4meplfW"
      },
      "source": [
        "This piece of code ensures that the generated graph is free of axis lines, ticks, and labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbHXRNh1282_"
      },
      "outputs": [],
      "source": [
        "# Hide axes\n",
        "ax.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA72NzRb3Cy3"
      },
      "source": [
        "## Module: Create a Legend and Display the Plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-vsGZ4lsfGB"
      },
      "source": [
        "The first line of code creates a list of `handles`, objects that can be used in a legend. The `handles` being created here are small rectangles of color according to the corresponding species.\n",
        "\n",
        "The second line extracts the labels for the legend from the `species_counts` DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0xMiTxVrJ8k"
      },
      "outputs": [],
      "source": [
        "# Create a legend\n",
        "handles = [plt.Rectangle((0, 0), 1, 1, color=colors[i]) for i in range(num_categories)]\n",
        "labels = species_counts[\"SpeciesList\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCvkh-x6slHP"
      },
      "source": [
        "This code anchors the bounding box to the center left of the remaining space and sets the title of the legend as \u2018Species\u2019."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TTgFsXdrLRO"
      },
      "outputs": [],
      "source": [
        "ax.legend(handles, labels, loc='center left', bbox_to_anchor=(1, 0.5), title=\"Species\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WS8kKnLtHA4"
      },
      "source": [
        "To display the final plot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "executionInfo": {
          "elapsed": 52085,
          "status": "ok",
          "timestamp": 1718047867164,
          "user": {
            "displayName": "Ryleigh Bruce",
            "userId": "04866625339349492872"
          },
          "user_tz": 300
        },
        "id": "kWftKntbc4Kg",
        "outputId": "7fb911f2-853c-4aae-89e0-8a0624a9255f"
      },
      "outputs": [],
      "source": [
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0KMrUXoNS53"
      },
      "source": [
        "#Creating a Treemap for Each Season"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExKpX2xlNbWD"
      },
      "source": [
        "The same modules will need to be installed as when a single graph was being created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 6400,
          "status": "ok",
          "timestamp": 1718228395642,
          "user": {
            "displayName": "Ryleigh Bruce",
            "userId": "04866625339349492872"
          },
          "user_tz": 300
        },
        "id": "Pv2XgyXWHQTr",
        "outputId": "4fff18c3-dde2-47ab-bd37-a5d6f20ba9b6"
      },
      "outputs": [],
      "source": [
        "!pip install squarify\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import squarify\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd-At6c1O_GS"
      },
      "source": [
        "Here the script uses the `pandas` library to transform the information in the Excel file into a two-dimensional DataFrame, just as it did in the previous script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQJoBjf_OrP7"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "df = pd.read_excel(\"./combined_animals.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcFnlzqpO_Yz"
      },
      "source": [
        "The \u2018Date\u2019 column from the DataFrame is then converted into datetime format using the `pd.to_datetime function`. The script then replaces the original \u2018Date\u2019 column with the data newly converted in datetime format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuudaAdMTYfK"
      },
      "source": [
        "## Module: Manipulating the DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4C_W-ySOr-c"
      },
      "outputs": [],
      "source": [
        "# Convert dates to datetime\n",
        "df['Date'] = pd.to_datetime(df['Date'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fh9pfdt5O_zp"
      },
      "source": [
        "The `get_season()` function uses the month data in integer format and returns a string representing the seasons the given month falls in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tweGFRpZOt0q"
      },
      "outputs": [],
      "source": [
        "# Define a function to determine the season based on the month\n",
        "def get_season(month):\n",
        "    if month in (12, 1, 2):\n",
        "        return 'Winter'\n",
        "    elif month in (3, 4, 5):\n",
        "        return 'Spring'\n",
        "    elif month in (6, 7, 8):\n",
        "        return 'Summer'\n",
        "    elif month in (9, 10, 11):\n",
        "        return 'Autumn'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq7hTp7LPAKg"
      },
      "source": [
        "The `df[\u2018Date\u2019].dt.month` function extracts the month from the \u2018Date\u2019 column within the DataFrame and `.apply(get_season)` applies the function defined previously to convert the month data into its season, creating a new \u2018Season\u2019 column within the DataFrame to store the converted information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4VpPv0UOvY7"
      },
      "outputs": [],
      "source": [
        "# Apply the season function to each date\n",
        "df['Season'] = df['Date'].dt.month.apply(get_season)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21xSZt2UPAlX"
      },
      "source": [
        "The DataFrame is then filtered to only include information relevant to the desired location ID (here it is location 7) with the code `df['locationID'] == location_id`. This is done by creating a Boolean series comparing the \u2018locationID\u2019 column in the DataFrame to the location_id variable. In rows where the value is the same, it will be \u2018True\u2019, and \u2018False\u2019 for all other values. The returned DataFrame is then assigned to the `df` variable for later use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grUeM8-BOxUw"
      },
      "outputs": [],
      "source": [
        "# Specify the locationID for filtering and title\n",
        "location_id = 7\n",
        "df = df[df['locationID'] == location_id]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt913O9gPA3T"
      },
      "source": [
        "Here a DataFrame is created called `seasonal_species_counts` by grouping the original DataFrame by the \u2018Season\u2019 and \u2018SpeciesList\u2019 columns. Rows with the same unique combination of \u2018Season\u2019 and \u2018SpeciesList\u2019 are then grouped together. The `agg` function is then used to calculate the sum for the \u2018SpeciesCount\u2019 value in each of the grouped rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKjxDNIHOzT_"
      },
      "outputs": [],
      "source": [
        "# Group data by season and species and sum species counts\n",
        "seasonal_species_counts = df.groupby(['Season', 'SpeciesList']).agg({'SpeciesCount': 'sum'}).reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_b93ra7PBM9"
      },
      "source": [
        "The first line retrieves the unique species in the \u2018SpeciesList\u2019 column of the DataFrame `seasonal_species_counts` and assigns them to the variable `unique_species`.Then the get_cmpa function is used in the next line to import the \u2018tab20c\u2019 colormap in order to assign a unique color to each species. In the final line of the code block, a dictionary is created where each key is a species name from the `unique_species` variable and the value is a color from the imported colormap."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVGv6ZWuO1L_"
      },
      "outputs": [],
      "source": [
        "# Determine the maximum number of unique species across all seasons\n",
        "unique_species = seasonal_species_counts['SpeciesList'].unique()\n",
        "color_map = plt.get_cmap('tab20c')\n",
        "colors = {species: color_map(i % color_map.N) for i, species in enumerate(unique_species)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT73HeuBPBdb"
      },
      "source": [
        "Here the script determines the maximum number of sightings for each season across all species and stores those values in the `max_total value`. In cases where a season is missing information, the value is automatically set to 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmU4-sNrO29Z"
      },
      "outputs": [],
      "source": [
        "# Get the total of sightings in each season to scale the plots\n",
        "season_totals = seasonal_species_counts.groupby('Season')['SpeciesCount'].sum().reindex(['Winter', 'Spring', 'Summer', 'Autumn'], fill_value=0)\n",
        "max_total = season_totals.max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCiREA1PPB4f"
      },
      "source": [
        "## Module: Preparing to Plot the Treemaps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQRnE1-kX_Ar"
      },
      "source": [
        "The following code blocks prepare a plot for each of the treemaps that corresponds with the volume of sightings for the given season. for season in season_totals.index iteratively processes each season stored in the season_total variable. The script then selects only the rows from seasonal_species_count where the season matches the current iteration\u2019s season. If there is recorded information to plot, `base_size = 5` and `fig_size = base_size * (season_totals[season] / max_total)` set the size of the plot based on the total spotted species for a season. The previously assigned colors are then retrieved and the treemap is generated using the calculated sizes and colors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF_sWqllyVeE"
      },
      "source": [
        "`ax.set_title(f'{season} (Total Sightings: {season_totals[season]:,.0f})')` ensures that the correct season is printed for each graph, and `axis(\u2018off\u2019)` removes unnecessary axis labels to increase legibility."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUZH8fm6yXAs"
      },
      "source": [
        "If there is no information recorded for a given season, the script will skip over the previous steps and simply print \u201cNo information gathered for `{season}` at Location `{location_id}`.\u201d and continue on to the next season."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edbVIuVOO4ks"
      },
      "outputs": [],
      "source": [
        "# Plotting\n",
        "for season in season_totals.index:\n",
        "    group = seasonal_species_counts[seasonal_species_counts['Season'] == season]\n",
        "    if not group.empty:\n",
        "        base_size = 5  # Base size for the smallest season graph\n",
        "        # Scaling the figure size based on the relative volume of sightings\n",
        "        fig_size = base_size * (season_totals[season] / max_total)\n",
        "        fig, ax = plt.subplots(figsize=(fig_size, fig_size))\n",
        "\n",
        "        sizes = squarify.normalize_sizes(group['SpeciesCount'], season_totals[season], season_totals[season])\n",
        "        plot_colors = [colors[species] for species in group['SpeciesList']]\n",
        "\n",
        "        squarify.plot(sizes=sizes, color=plot_colors, alpha=0.8, pad=0.5, ax=ax)\n",
        "        ax.set_title(f'{season} (Total Sightings: {season_totals[season]:,.0f})')\n",
        "        ax.axis('off')\n",
        "    else:\n",
        "        print(f\"No information gathered for {season} at Location {location_id}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1_CIPyRPCXF"
      },
      "source": [
        "## Module: Creating the Legend and Displaying the Treemap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfQppBl8ZhQi"
      },
      "source": [
        "The script creates several rectangular handles that correspond with the colors used in the treemap to depict the species. `fig.legend(handles, unique_species, loc='upper right', bbox_to_anchor=(1.2, 1), title=\"Species\")` creates a legend with the handles and corresponding labels and locates it at the upper right-hand corner outside of the plot area. `plt.subplots_adjust(right=0.85)` adjusts the parameters of the subplot to ensure that there is enough room to place the legend. The plot and legend are then displayed using the `plt.show()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "executionInfo": {
          "elapsed": 70462,
          "status": "ok",
          "timestamp": 1718228469459,
          "user": {
            "displayName": "Ryleigh Bruce",
            "userId": "04866625339349492872"
          },
          "user_tz": 300
        },
        "id": "35WyUL9MCAv_",
        "outputId": "d7789950-bbd8-4158-b31c-924d787cc8c3"
      },
      "outputs": [],
      "source": [
        "# Legend for the species\n",
        "handles = [plt.Rectangle((0, 0), 1, 1, color=color_map(i % color_map.N)) for i, species in enumerate(unique_species)]\n",
        "fig.legend(handles, unique_species, loc='upper right', bbox_to_anchor=(1.2, 1), title=\"Species\")\n",
        "\n",
        "plt.subplots_adjust(right=0.85)  # Adjust subplot sizes to fit legend\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMUosu7+eQvobOos3KEJ82d",
      "collapsed_sections": [
        "-_5YYXzbo5JJ",
        "5ljq48eDTKlU",
        "n26ppiTZ2rRK",
        "npVRYLnF23XL",
        "DPUEqlGO27ei",
        "jA72NzRb3Cy3",
        "TuudaAdMTYfK"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}